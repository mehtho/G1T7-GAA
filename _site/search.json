[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Project Overview",
    "section": "",
    "text": "The distribution of Singaporean amenities has changed according to the distribution of different demographics. For example, older towns with older residents tend to be closer to wet markets, since the new traditional wet markets were only constructed until 1984. However, aggregated public knowledge of such patterns with easy to understand spatial representations are limited. The limited access to such information in easily understandable formats may result in public misconceptions and increasingly difficult communication regarding plans for future developments.\nWhatTown involves Geographical Accessibility Modelling and Spatial Point Pattern Analysis to determine the coverage of various facilities and amenities essential to daily living in Singaporean neighbourhoods using publicly available data. This data encompasses supermarkets, wet markets, hawker centres, and other points of interest. WhatTown aims to be a web application to guide users through the process of Exploratory Data Analysis, Geographical Accessibility Modelling, and Kernel Density Estimation without any technical skill requirements.\nThe flexibility offered by our application will allow users to address their specific, unique questions through intuitive and simple visualisations."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html#abstract",
    "href": "index.html#abstract",
    "title": "Project Proposal",
    "section": "",
    "text": "WhatTown involves Geographical Accessibility Modelling and Spatial Point Pattern Analysis to determine the coverage of various facilities and amenities essential to daily living in Singaporean neighbourhoods.\nThis will be done on publicly available data, encompassing supermarkets, wet markets, hawker centres, and other points of interest.\nWhatTown aims to be a web application to guide users through the process of Exploratory Data Analysis, Geographical Accessibility Modelling, and Kernel Density Estimation without any technical skills required.\nThe flexibility offered by our application will allow users to address their specific, unique questions through intuitive and simple visualisations without any knowledge of code or algorithms."
  },
  {
    "objectID": "index.html#problem-motivation",
    "href": "index.html#problem-motivation",
    "title": "Project Overview",
    "section": "Problem & Motivation",
    "text": "Problem & Motivation\n\nSingaporean amenities are built to serve nearby resident populations, whose needs and behaviors change across generations. For example, there has been a gradual shift in popularity from wet markets to supermarkets, which is clear in younger estates such as Punggol, with fewer wet markets than some older estates. While this is partially due to shifts in public policy surrounding urban development, these trends also reflect significant intergenerational behavioural changes, such as the younger generation’s affinity for supermarkets.\nHowever, public knowledge of such trends largely anecdotal, reflecting and individual’s experience rather than aggregated data. To reduce unnecessary variance in public knowledge on the availability of amenities, we propose a geospatial analytics application that allows users to address their various curiosities by visualising differences and patterns across Singapore."
  },
  {
    "objectID": "index.html#objectives",
    "href": "index.html#objectives",
    "title": "Project Overview",
    "section": "Objectives",
    "text": "Objectives\n\nWe would like to build an interactive tool to allow users to\n\nCompare the prevalence of different sources of necessities in different neighbourhoods\nVisualise the coverage and convenience of different sources of necessities with a neighbourhood"
  },
  {
    "objectID": "index.html#main-features",
    "href": "index.html#main-features",
    "title": "Project Overview",
    "section": "Main Features",
    "text": "Main Features\n\nTo meet the aforementioned objectives, we proposed 3 features of our applications.\n\nExploratory Data Analysis (Shared)\n\nFilter points by type (e.g. supermarket, wet markets, etc.) and region\nPlot these points on a map\nPlot histograms of the number of points of interest\n\nSpatial Points Pattern Analysis (Chester)\n\nGenerate KDE maps for certain facilities\nPerform 2nd Order Spatial Points Pattern Analysis\nAllow map interaction for users to easily access demographic information (age distribution)\n\nGeographical Accessibility Modelling (Matt)\n\nSelect facilities to model accessibility for\nChoose between differently sized hexagons and squares\nAllow users to choose between Hansen’s, KD2SFCA and SAM accessibility modelling methods"
  },
  {
    "objectID": "index.html#datasets",
    "href": "index.html#datasets",
    "title": "Project Overview",
    "section": "Datasets",
    "text": "Datasets\n\n\nSpatial\n\nSupermarkets (2019)\n\nGovernment Data on Supermarkets\n\nMarkets & Food Centres (2023)\n\nGovernment Data on Wet Markets and Food Centres, including Hawker Centres\n\nMaster Plan 2019 Subzones (2019)\n\nGeospatial data consisting of Singapore’s planning areas, subzones, and boundaries\n\nLand & Transport Singapore (LTSG) dataset (2022)\n\nAn extensive dataset containing the locations of various points of interest around Singapore\n\n\n\n\nAspatial\n\nSingapore Census of Population (2020)\n\nIncludes data such as the population of various neighbourhoods and the distribution of age groups within"
  },
  {
    "objectID": "index.html#literature-reviews",
    "href": "index.html#literature-reviews",
    "title": "Project Overview",
    "section": "Literature Reviews",
    "text": "Literature Reviews\n\nNo Longer “Dirty, Unhygienic, Crowded and Messy”: The Story of Singapore’s Changing Wet Markets\nIn 1981, it was decided that no more new wet markets would be built, and the last 2 traditional wet markets in Jurong were built in 1984. Some reasons highlighted were labour and time efficiency. Time efficiency is particularly interesting, as they mentioned that due to the new trend of dual-income families, marketing had to become a faster and more efficient activity, replacing the notion of a wife spending the day at the market.\nThe article also mentioned the issue of succession despite a sentimental attachment to wet markets.\nIN FOCUS: Is there a future for Singapore’s wet markets?\nIn 2011, the government announced that it would continue building wet markets but focus more on the food-centre aspect, providing affordable food options in areas lacking them.\nFrom the above articles, we can see that certain estates developed between 1984 and 2011 may lack food centres and wet markets. We can also expect some food centres in newer estates. This motivates the use of spatial clustering to observe these patterns and confirm or disprove our intuition.\nThis article also motivates the inclusion of supermarkets, wet markets, and food centres in our clustering criteria\nBarriers to the advancement of modern food retail formats:Theory and measurement\nIn this study, it was noted that supermarkets have been adopted across all age groups but not far into the perishable products category. However, this study was not done using data from Singapore, which may yield different results. While this study used a different method from kernel density estimation to estimate the coverage of supermarkets, we believe it is a simple method to approximate the demand for wet markets. This is because if a wet market did not have enough demand and customer footfall to sustain itself, it would close down or be replaced, perhaps by a food centre.\nInspired by this article, we would like to pay more attention to the theoretical coverage provided by wet markets and supermarkets."
  },
  {
    "objectID": "index.html#system-architecture",
    "href": "index.html#system-architecture",
    "title": "Project Overview",
    "section": "System Architecture",
    "text": "System Architecture"
  },
  {
    "objectID": "index.html#ui-wireframes",
    "href": "index.html#ui-wireframes",
    "title": "Project Overview",
    "section": "UI Wireframes",
    "text": "UI Wireframes\n\n\nEDAKDEAccessibility Modelling\n\n\n\n\n\n\n\n\n\n\n\n\n\nAcknowledgements\nBackground image created with Canva AI!"
  },
  {
    "objectID": "prototypes/Wrangling.html",
    "href": "prototypes/Wrangling.html",
    "title": "WhatTown",
    "section": "",
    "text": "TODO (In order of priority):\n\nMPSZ 2019\n\nMake 3 Hexagon Layers (250, 400, 750m)\nCalculate Distance Matrices w/ naive demand\n\nHave the raw Euclidean distance matrix\nConvert into inverse and exponential distance decay (Give 5 options)\n\n\nMarket & Food Centers\nSupermarkets\n\n\npacman::p_load(tidyverse, tmap, sf, dplyr, smoothr)\n\nReference: Matt’s Takehome Exercise 1\n\nmpsz &lt;- st_read(\"../data/geospatial/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\") %&gt;% \n  mutate(Match=str_match_all(Description,\"&lt;td&gt;(.*?)&lt;/td&gt;\")) %&gt;% \n  mutate(Match=map(Match, ~ .[,2])) %&gt;% \n  mutate(Match=map(Match,setNames,c(\"SUBZONE_NO\",\"SUBZONE_N\",\"SUBZONE_C\", \"CA_IND\", \"PLN_AREA_N\", \"PLN_AREA_C\", \"REGION_N\", \"REGION_C\", \"INC_CRC\", \"FMEL_UPD_D\"))) %&gt;% \n  unnest_wider(Match) %&gt;%\n  st_as_sf() %&gt;% dplyr::select('Name', 'geometry', 'SUBZONE_NO', 'SUBZONE_N', 'PLN_AREA_N', 'PLN_AREA_C', 'REGION_N', 'REGION_C') %&gt;% \n  st_make_valid() %&gt;%\n  st_zm() %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `/Users/matthewho/Work/Y3S2/IS415/Project/G1T7-GAA/data/geospatial/MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nwrite_rds(mpsz, '../data/rds/mpsz.rds')\n\nReference: Matt’s Takehome Exercise 1\n\nmainland_sg &lt;- st_union(mpsz) %&gt;%\n    st_cast(\"POLYGON\")\n\nmainland_sg &lt;- mainland_sg[c(10)]\nmainland_sg &lt;- fill_holes(mainland_sg, units::set_units(1, \"km^2\"))\nmainland_sg &lt;- st_as_sf(mainland_sg)\n\nReferences: https://r-spatial.github.io/sf/reference/st_make_grid.html https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/paste\n\nsg_2_grid &lt;- function(sg, g_size, is_square, name) {\n  grids &lt;- st_make_grid(sg, cellsize = g_size, square = is_square) %&gt;%\n  st_intersection(mainland_sg)\n  \n  write_rds(grids, paste(name, '.rds', sep = \"\"))\n  plot(grids)\n  \n  return(grids)\n}\n\ngrid_2_dist_mat &lt;- function(grid, name) {\n  dm &lt;- dist(st_coordinates(st_centroid(grid)))\n  write_rds(dm, paste(name, '_dm.rds', sep = \"\"))\n  return(dm)\n}\n\nReferences: https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/dist https://www.rdocumentation.org/packages/geosphere/versions/1.5-18/topics/centroid\n\ngrids_and_dist_matrices &lt;- function(sg, g_size, is_square) {\n  name &lt;- paste('../data/rds/grid_', g_size, ifelse(is_square, \"_square\", \"_hexagon\"), sep = \"\")\n  \n  grid &lt;- sg_2_grid(sg, g_size, is_square, name)\n  distance_matrix &lt;- grid_2_dist_mat(grid, name)\n}\n\n\ngrids_and_dist_matrices(mainland_sg, 700, FALSE)"
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Project Overview",
    "section": "",
    "text": "The distribution of Singaporean amenities has changed according to the distribution of different demographics. For example, older towns with older residents tend to be closer to wet markets, since the new traditional wet markets were only constructed until 1984. However, aggregated public knowledge of such patterns with easy to understand spatial representations are limited. The limited access to such information in easily understandable formats may result in public misconceptions and increasingly difficult communication regarding plans for future developments.\nWhatTown involves Geographical Accessibility Modelling and Spatial Point Pattern Analysis to determine the coverage of various facilities and amenities essential to daily living in Singaporean neighbourhoods using publicly available data. This data encompasses supermarkets, wet markets, hawker centres, and other points of interest. WhatTown aims to be a web application to guide users through the process of Exploratory Data Analysis, Geographical Accessibility Modelling, and Kernel Density Estimation without any technical skill requirements.\nThe flexibility offered by our application will allow users to address their specific, unique questions through intuitive and simple visualisations."
  },
  {
    "objectID": "prototypes/THE3.html",
    "href": "prototypes/THE3.html",
    "title": "Take-Home Exercise 3",
    "section": "",
    "text": "Update: The prototype has been deployed on https://matthewhosmu.shinyapps.io/G1T7-WhatTown/"
  },
  {
    "objectID": "prototypes/THE3.html#overview-and-objectives",
    "href": "prototypes/THE3.html#overview-and-objectives",
    "title": "Take-Home Exercise 3",
    "section": "Overview and Objectives",
    "text": "Overview and Objectives\nIn this takehome exercise, I will be prototyping my accessibility modelling module for the Geospatial Analytics Project.\nThis prototype module aims to\n\nModel the accessibility to various amenties across Singapore\nShow the distributions of accessibility to amenities across regions\nChoose between Hexagonal and Square Grids\nChange the desired grid size\nChoose different distance decay functions\nChoose between Hansen’s, KD2SFCA and SAM accessibility modelling methods"
  },
  {
    "objectID": "prototypes/THE3.html#data-wrangling",
    "href": "prototypes/THE3.html#data-wrangling",
    "title": "Take-Home Exercise 3",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\nDependencies\nGiven that this application will be deployed on shiny, I tried to reduce the number of packages to only those that are absolutely necessary or provide sufficient value to the project.\n\nTidyverse\n\nIncludes common packages for datascience, particularly ggplot2, tibble and dplyr\n\ntmap\n\nGenerates colorful and easy to use maps to help our users tell the stories that they want to\n\nsf\n\nEssential for handling spatial features\n\nsmoothr\n\nUsed to remove holes and slithers in geometry\n\nSpatialAcc\n\nThe most promiently featured package in this project. SpatialAcc provides a set of spatial accessibility modelling methods.\n\nhash\n\nI use this to make simple key value pairs, which will map shorter parameter names to files. Using the right data structures can make my code simpler and cleaner\n\ncowplot\n\nUsed to combine different types of plots, e.g. tmap and ggplot\n\n\n\npacman::p_load(tidyverse, tmap, sf, smoothr, SpatialAcc, hash, cowplot)\n\n\n\nDatasets\n\n\nSpatial\n\nSupermarkets (2019)\n\nGovernment Data on Supermarkets. This dataset contains the license names of each supermarket, ensuring a certain degree of standardisation and allows us to check the distribution of different supermarket types in Singapore.\n\nMarkets & Food Centres (2023)\n\nGovernment Data on Wet Markets and Food Centres, including Hawker Centres. This dataset contains data on the type and number of stalls in each location.\n\nMaster Plan 2019 Subzones (2019)\n\nGeospatial data consisting of Singapore’s planning areas, subzones, and boundaries. This dataset will be used to define the boundaries of singapore and its subregions and mapped to the data in the population census.\n\nLand & Transport Singapore (LTSG) dataset (2022)\n\nAn extensive dataset containing the locations of various points of interest around Singapore. For this dataset, only points relevant to daily life for the average person will be considered.\n\n\n\n\nAspatial\n\nSingapore Census of Population (2020)\n\nPopulation of various neighbourhoods and the distribution of age groups within. The distribution of age groups will not be used in this segment. Only the total population will be considered for each region.\n\n\n\n\nMaster Plan Subzone Dataset\nThe master plan subzone dataset contains Singapore’s geometry and the boundaries of each planning zone and subzone. These correspond with other aspatial datasets such as the population census.\nTo prepare the MPSZ dataset, several steps are taken\n\nParse the kml fields\nRemove the z coordinate\nFix the CRS\nFix invalid geometry\nWrite it to an rds file\n\n\nmpsz &lt;- st_read(\"data/geospatial/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\") %&gt;% \n  mutate(Match=str_match_all(Description,\"&lt;td&gt;(.*?)&lt;/td&gt;\")) %&gt;% \n  mutate(Match=map(Match, ~ .[,2])) %&gt;% \n  mutate(Match=map(Match,setNames,c(\"SUBZONE_NO\",\"SUBZONE_N\",\"SUBZONE_C\", \"CA_IND\", \"PLN_AREA_N\", \"PLN_AREA_C\", \"REGION_N\", \"REGION_C\", \"INC_CRC\", \"FMEL_UPD_D\"))) %&gt;% \n  unnest_wider(Match) %&gt;%\n  st_as_sf() %&gt;% dplyr::select('Name', 'geometry', 'SUBZONE_NO', 'SUBZONE_N', 'PLN_AREA_N', 'PLN_AREA_C', 'REGION_N', 'REGION_C') %&gt;% \n  st_zm() %&gt;%\n  st_transform(crs = 3414) %&gt;%\n  st_make_valid() %&gt;%\n  write_rds('data/rds/mpsz.rds')\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `/Users/matthewho/Work/Y3S2/IS415/Project/G1T7-GAA/prototypes/data/geospatial/MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nAfter parsing the mpsz dataset, we can now combine it with the population census of 2020 dataset.\nDisclaimer:\nThe Population Census dataset, referred to as pop2020 in this take home exercise was created by my teammate during the data wrangling process for our project. All data wrangling mentioned in this take-home exercise is my original work. Data that was not wrangled by me will be marked and imported as an rds.\n\n\nPopulation Census Dataset Integration\nIn some accessibility modelling works, demand is naively and uniformly allocated across the relevant geometry, i.e allocating a constant demand over each part of the study area. This would cause the result to be similar to Kernel Density Estimation.\nTo avoid this issue, and to go beyond naive demand estimation, I have decided to allocate ‘demand’ to each subzone or planning area according to the record population of the area in the population census dataset.\nThis will be done by mapping the population estimations of the census to the corresponding polygons in the mpsz dataset. This will be conducted on two levels of granularity.\n\nSubzones\nPlanning Areas\n\nTo incorporate a demand estimation into accessibility modelling, I determine a population density estimate for every polygon.\n\nPlanning Area LevelSubzone Level\n\n\nTo prepare the dataset at the planning area level, we can - Extract the total population from the “Total” row, converted to a numerical value - Accumulate the collective populations and sub-polygons of every planning area\n\nMerge the mpsz and population datasets based on planning area names\nDerive a population density estimate, divide the population of the area by the area\n\n\npop2020_pa &lt;- read_rds('data/rds/pop2020.rds') %&gt;%\n  mutate(Total = as.numeric(Total)) %&gt;%\n  group_by(Planning_Area) %&gt;%\n  summarise(Total = sum(Total), .groups = \"drop\")\n\nmpsz_pa &lt;- mpsz %&gt;%\n  group_by(PLN_AREA_N) %&gt;%\n  summarise(geometry = st_union(geometry), .groups = \"drop\") %&gt;% \n  merge(pop2020_pa, by.x=\"PLN_AREA_N\", by.y=\"Planning_Area\") %&gt;% \n  mutate(Total = as.numeric(Total),\n           area = st_area(geometry), \n           pop_dens = Total / area)\n\nmpsz_pa$area &lt;- st_area(mpsz_pa$geometry)\nmpsz_pa$pop_dens &lt;- mpsz_pa$Total / mpsz_pa$area\n\nwrite_rds(mpsz_pa, 'data/rds/mpsz_pa.rds')\n\n\n\n\nThis process is similar to the aforementioned planning area population census integration.\n\n\npop2020_sz &lt;- read_rds('data/rds/pop2020.rds') %&gt;%\n  mutate(Total = as.numeric(Total)) %&gt;%\n  group_by(Subzone) %&gt;%\n  summarise(Total = sum(Total), .groups = \"drop\")\n\nmpsz_sz &lt;- mpsz %&gt;%\n  group_by(SUBZONE_N) %&gt;%\n  summarise(geometry = st_union(geometry), .groups = \"drop\") %&gt;% \n  merge(pop2020_sz, by.x=\"SUBZONE_N\", by.y=\"Subzone\") %&gt;% \n  mutate(Total = as.numeric(Total),\n           area = st_area(geometry), \n           pop_dens = Total / area)\n\nmpsz_sz$area &lt;- st_area(mpsz_sz$geometry)\nmpsz_sz$pop_dens &lt;- mpsz_sz$Total / mpsz_sz$area\n\nwrite_rds(mpsz_sz, 'data/rds/mpsz_sz.rds')\n\n\n\n\n\n\nGetting Mainland Singapore\nGiven that the outer islands are not relevant to accessibility, since traversing water is significantly different from land travel. The population of these island is also low enough that they are unlikely to affect the results of our modelling process.\nReference: Matt’s TakeHome Exercise 1\n\nmainland_sg &lt;- st_union(mpsz_pa) %&gt;%\n    st_cast(\"POLYGON\")\n\nmainland_sg &lt;- mainland_sg[c(15)] %&gt;% \n  fill_holes(units::set_units(1, \"km^2\")) %&gt;%\n  st_as_sf() %&gt;%\n  write_rds('data/rds/mainland_sg.rds')\n\nplot(mainland_sg)"
  },
  {
    "objectID": "prototypes/THE3.html#grid-generation-process",
    "href": "prototypes/THE3.html#grid-generation-process",
    "title": "Take-Home Exercise 3",
    "section": "Grid Generation Process",
    "text": "Grid Generation Process\nThe accessibility modelling process requires a grid. This grids segment the relevant study area into polygons of various sizes, typically hexagons or squares. Hexagons have the added benefit of supporting diagonal adjacency.\nFor the project module, I would like to provide grid options such as size and shape of the grid. Since the grid generation process is relatively unchanging but time consuming, the grids will be pre-calculated with several parameters and combined with other dynamic elements at runtime.\nThe follow functions have been written with the project module in mind. This section will discuss the design of each of these functions before a technical demonstration of these functions.\n\nFunction to add “demand”\nA grid polygon, such as a square or hexagon, may overlap the singaporean mainland partially or overlap multiple sub-areas at once. Based on the concept of population density, a grid with a partial overlap with a subzone or planning area should have a lower population estimation than a grid with a full overlap. A grid’s population should also be a function of the populations of every zone it overlaps as well.\nTherefore, I have designed the following functions to allocate density to each grid polygon.\nGiven the set of \\(n\\) grid polygons \\(G = \\{g_0, g_1, ..., g_n\\}\\), and set of \\(m\\) subzone or planning areas \\(Z = \\{z_0, z_1, ..., z_m\\}\\).\nThe population of a grid \\(g_i\\) is given as \\(Pop(g_i)\\), The density of a subzone or planning area \\(z_i\\) is given as \\(Dens(z_i)\\) The area of the intersection between a grid \\(g_i\\) and subzone or planning area \\(z_i\\) is given as \\(AreaInt(g_i, z_i)\\)\n\\(Pop(g_i) = \\sum^m_{j=0} AreaInt(g_i, z_j) * Dens(z_j) \\quad \\forall g_i \\in G\\)\nThis function can be compared to a weighted mean of populations, weighted by intersection area and is implemented below.\nThe result is a grid with a field ‘demand’ corresponding to the result of this function.\n\nadd_weights &lt;- function(grids, pop) {\n  joined &lt;- st_join(grids, pop, join = st_intersects)  %&gt;%\n    mutate(intersect_area = st_area(x),\n           demand = intersect_area * pop_dens) %&gt;%\n    st_drop_geometry()\n  \n  grids &lt;- grids %&gt;%\n    left_join(joined %&gt;%\n                group_by(ID) %&gt;%\n                summarise(total_demand = sum(demand)),\n              by = \"ID\") %&gt;%\n    mutate(demand = ifelse(is.na(total_demand), 0, total_demand)) %&gt;%\n    select(-total_demand)\n}\n\n\n\nMake a grid over mainland Singapore\nThis function generates a grid over the bounding box of mainland Singapore. However, most of the bounding box covers irrelevant areas, or the ocean. We reduce the grid, and cut grid polygons to fit the outline of mainland Singapore.\nReferences: https://r-spatial.github.io/sf/reference/st_make_grid.html\n\nsg_2_grid &lt;- function(sg, g_size, is_square, name, pop) {\n  grids &lt;- st_make_grid(sg, cellsize = g_size, square = is_square) %&gt;%\n  st_intersection(mainland_sg) %&gt;%\n  st_as_sf() %&gt;%\n    mutate(demand = 0, ID = row_number())\n  \n  grids_w_demand &lt;- add_weights(grids, pop) %&gt;%\n  rename(geometry = x)\n  \n  write_rds(grids_w_demand, paste(name, '.rds', sep = \"\"))\n  \n  return(grids_w_demand)\n}\n\n\n\nGenerate the grids and distance matrices\nThis wrapper function called the aforementioned functions to generate grids of different sizes and shapes and saves them as rds files to be loaded at runtime.\nReferences: https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/dist https://www.rdocumentation.org/packages/geosphere/versions/1.5-18/topics/centroid\n\ngrids_and_dist_matrices &lt;- function(sg, pop, g_size, is_square, subz) {\n  name &lt;- paste('data/rds/grid_', g_size, ifelse(is_square, \"_square\", \"_hexagon\"), ifelse(subz, \"_sz\", \"_pa\"), sep = \"\")\n  grid &lt;- sg_2_grid(sg, g_size, is_square, name, pop)\n  return(grid)\n}\n\n\n\nWriting the grids with population as demand\nMultiple grids of varying sizes and shapes weighted by subzone or planning area populations can be easily generated by calling the functions as done below.\n\nfor(di in c(250, 500, 750, 1000)) {\n  grids_and_dist_matrices(mainland_sg, mpsz_sz, di, FALSE, TRUE)\n  grids_and_dist_matrices(mainland_sg, mpsz_sz, di, TRUE, TRUE)\n  grids_and_dist_matrices(mainland_sg, mpsz_pa, di, FALSE, FALSE)\n  grids_and_dist_matrices(mainland_sg, mpsz_pa, di, TRUE, FALSE)\n}\n\n\n\nFunctional Demo\nIn this functional demo, each function and its code have been called sequentially to illustrate the flow of how the data wrangling results in useful information.\n\ndemo &lt;- grids_and_dist_matrices(mainland_sg, mpsz_sz, 500, FALSE, TRUE)\n\ntm_shape(demo) + \n  tm_fill(col='demand',\n            n = 7,\n            style = \"quantile\",\n            border.col = \"black\",\n            border.lwd = 1,\n            na.rm = TRUE)"
  },
  {
    "objectID": "prototypes/THE3.html#step-by-step-demo",
    "href": "prototypes/THE3.html#step-by-step-demo",
    "title": "Take-Home Exercise 3",
    "section": "Step by Step Demo",
    "text": "Step by Step Demo\n\nGenerating the grid\nObserve that the results of st_make_grid create a grid over the entire bounding box of the study area.\n\ngrids &lt;- st_make_grid(mainland_sg, cellsize = 500, square = FALSE)\nplot(grids)\n\n\n\n\n\n\n\n\nAfter using st_intersection to remove irrelvant hexagons and trim hexagons to fit the countours of mainland Singapore, we introduce the demand parameter to each hexagon. Each hexagon is also assigned a numerical identifier to make joining processes later easier. At this state, the demand is uniformly 0 since the population of each area has not been accounted for yet.\n\n\nTrimming the Grid\n\ngrids &lt;- grids %&gt;%\nst_intersection(mainland_sg) %&gt;%\nst_as_sf() %&gt;%\n  mutate(demand = 0, ID = row_number())\n\ntm_shape(grids) + \n  tm_polygons(col='demand',\n            n = 7,\n            style = \"quantile\",\n            border.col = \"black\",\n            border.lwd = 1,\n            na.rm = TRUE)\n\n\n\n\n\n\n\n\n\n\nSingapore’s Population Density\nThe population of Singapore can be seen to vary greatly throughout areas. For example, the central catchment area is unsurprisingly empty, while residential areas in the West, North and East contain most of Singapore’s population.\n\ntm_shape(mpsz_sz) + \n  tm_polygons(col='Total',\n            n = 7,\n            style = \"quantile\",\n            border.col = \"black\",\n            border.lwd = 1,\n            na.rm = TRUE)\n\n\n\n\n\n\n\n\n\n\nCombining the Grid and Population Data\nSimilar to the code above, we allocate population estimates to each grid. This grid can be used for accessibility modelling methods.\n\ngrids_on_sz &lt;- st_join(grids, mpsz_sz, join = st_intersects)  %&gt;%\n  mutate(intersect_area = st_area(x),\n         demand = intersect_area * pop_dens) %&gt;%\n  st_drop_geometry()\n\ngrids &lt;- grids %&gt;%\n  left_join(grids_on_sz %&gt;%\n              group_by(ID) %&gt;%\n              summarise(total_demand = sum(demand)),\n            by = \"ID\") %&gt;%\n  mutate(demand = ifelse(is.na(total_demand), 0, total_demand)) %&gt;%\n  select(-total_demand) %&gt;%\nrename(geometry = x)\n\ntm_shape(grids) + \n  tm_polygons(col='demand',\n            n = 7,\n            style = \"quantile\",\n            border.col = \"black\",\n            na.rm = TRUE)\n\n\n\n\n\n\n\n\n\n\nHandling Points\nTo model the locations of amenities such as supermarkets, we need each amenity to be represented as a data point. As data regarding the size, or capacity of each facility is hard to come by, some types of amenities can have a fixed capacity.\nFor markets and food centres, data includes the number of stalls, which could correlate with size and capacity.\nIn this section, each dataset of point data is wrangled and the relevant columns extracted.\n\nSupermarketsMarkets and Food CentresMRTOther POIs\n\n\nSupermarket data processing includes the following steps:\n\nParse the KML data\nExtract the relevant rows\nMake valid, remove z coordinate, change CRS\nRemove invalid points\n\n\nsupermarkets &lt;- st_read(\"data/geospatial/SupermarketsKML.kml\") %&gt;% \n  mutate(Match=str_match_all(Description,\"&lt;td&gt;(.*?)&lt;/td&gt;\")) %&gt;% \n  mutate(Match=map(Match, ~ .[,2])) %&gt;% \n  mutate(Match=map(Match,setNames,c(\"LIC_NAME\", \"BLK_HOUSE\", \"STR_NAME\", \"UNIT_NO\", \"POSTCODE\", \"LIC_NO\", \"INC_CRC\", \"FMEL_UPD_D\"))) %&gt;% \n  unnest_wider(Match) %&gt;%\n  st_as_sf() %&gt;% \n  dplyr::select('LIC_NAME', 'geometry') %&gt;% \n  st_make_valid() %&gt;%\n  st_zm() %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `SUPERMARKETS' from data source \n  `/Users/matthewho/Work/Y3S2/IS415/Project/G1T7-GAA/prototypes/data/geospatial/SupermarketsKML.kml' \n  using driver `KML'\nSimple feature collection with 526 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6258 ymin: 1.24715 xmax: 104.0036 ymax: 1.461526\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\nsupermarkets &lt;- st_intersection(supermarkets, mainland_sg)\n\nCheck for NA values\n\nany(is.na(supermarkets))\n\n[1] FALSE\n\n\nCategorise supermarkets by major brand. Since the name of each supermarket is determined by the license, we can expect that small variations will not affect this method.\n\nsupermarkets$SUBTYPE &lt;- ifelse(grepl(\"FAIRPRICE\", supermarkets$LIC_NAME, ignore.case = TRUE), \"FAIRPRICE\",\n                     ifelse(grepl(\"COLD STORAGE\", supermarkets$LIC_NAME, ignore.case = TRUE), \"COLD STORAGE\",\n                            ifelse(grepl(\"SHENG SIONG\", supermarkets$LIC_NAME, ignore.case = TRUE), \"SHENG SIONG\", \"OTHER\")))\n\nwrite_rds(supermarkets, 'data/rds/supermarkets.rds')\n\nPlot of the supermarkets across Singapore\n\ntm_shape(mainland_sg) + \n  tm_polygons() + \n  tm_shape(supermarkets) + \n  tm_dots(col = \"SUBTYPE\", size = 0.05)\n\n\n\n\n\n\n\n\n\n\nMarkets and Food Centre geometry have been processed similarly to the supermarkets dataset, except that the TOTAL_STALLS parameter has been included to reflect the capacity of each facility.\n\nmarketandfc &lt;- st_read(\"data/geospatial/NEAMarketandFoodCentreKML.kml\") %&gt;% \n  mutate(Match=str_match_all(Description,\"&lt;td&gt;(.*?)&lt;/td&gt;\")) %&gt;% \n  mutate(Match=map(Match, ~ .[,2])) %&gt;% \n  mutate(Match=map(Match,setNames,c(\"TOTAL_STALLS\", \"MP_STALLS\", \"CF_STALLS\", \"POSTAL_CODE\", \"OWNER\", \"TYPE\", \"LOCATION_CENTRE\", \"NAME_OF_CENTRE\", \"INC_CRC\", \"FMEL_UP_D\"))) %&gt;% \n  unnest_wider(Match) %&gt;%\n  st_as_sf() %&gt;% dplyr::select(\"NAME_OF_CENTRE\", \"TYPE\", \"TOTAL_STALLS\", \"geometry\") %&gt;% \n  st_make_valid() %&gt;%\n  st_zm() %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MARKET_FOOD_CENTRE' from data source \n  `/Users/matthewho/Work/Y3S2/IS415/Project/G1T7-GAA/prototypes/data/geospatial/NEAMarketandFoodCentreKML.kml' \n  using driver `KML'\nSimple feature collection with 110 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.7105 ymin: 1.272589 xmax: 103.9882 ymax: 1.443405\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nCheck for NA values\n\nany(is.na(marketandfc))\n\n[1] FALSE\n\n\nAllocating a simpler type variable to each facility, similar to the supermarkets\n\nmarketandfc$SUBTYPE &lt;- ifelse(marketandfc$TYPE == \"HC\", \"HAWKER_CENTRE\",\n                  ifelse(marketandfc$TYPE == \"MHC\", \"MARKET_AND_HAWKER\",\n                         ifelse(marketandfc$TYPE == \"MK\", \"MARKET\", NA)))\nmarketandfc &lt;- subset(marketandfc, select = -TYPE)\n\nmarketandfc$TOTAL_STALLS &lt;- as.numeric(marketandfc$TOTAL_STALLS)\n\nwrite_rds(marketandfc, 'data/rds/markets_and_food_centres.rds')\n\n\ntm_shape(mainland_sg) + \n  tm_polygons() + \ntm_shape(marketandfc) + \n  tm_dots(col = \"SUBTYPE\", group = \"SUBTYPE\", size = \"TOTAL_STALLS\")\n\n\n\n\n\n\n\n\n\n\nMRT stations have been processed simply, without any additional parameters. This is because the entire MRT system is somewhat interconnected and station capacity does not often causes bottlenecks as much as the capacity of the trains.\n\nmrt &lt;- read.csv('data/aspatial/mrt.csv') %&gt;%\n  st_as_sf(coords = c(\"lng\", \"lat\"),\n                      crs = 4326) %&gt;%\n  st_transform(crs = 3414) %&gt;%\n  dplyr::select('name', 'geometry')\n\nwrite_rds(mrt, 'data/rds/mrt.rds')\n\n\nany(is.na(mrt))\n\n[1] FALSE\n\n\n\ntm_shape(mainland_sg) + \n  tm_polygons() + \ntm_shape(mrt) + \n  tm_dots(col = \"red\")\n\n\n\n\n\n\n\n\n\n\nWe found a large dataset consisting of many points of interest. We have extracted only the points of interest that may play a part in people’s routines. In this section, we choose only the relevant places, extract them, and save them for later use.\n\npoi &lt;- read.csv('data/aspatial/poi.csv') %&gt;%\n  st_as_sf(coords = c(\"lng\", \"lat\"),\n                      crs = 4326) %&gt;%\n  st_transform(crs = 3414)\n\n\npoi2type &lt;- function(pois, typ) {\n  poi &lt;- pois[pois[[typ]] == 'True', ] %&gt;%\n    dplyr::select('name', 'geometry')\n  write_rds(poi, paste('data/rds/poi_', typ, '.rds', sep=\"\"))\n}\n\n\npoi_types &lt;- c(\"restaurant\", \"hospital\", \"lodging\", \"bank\", \"cafe\", \"convenience_store\", \"clothing_store\", \"atm\", \"school\", \"beauty_salon\", \"place_of_worship\", \"tourist_attraction\", \"doctor\", \"dentist\", \"gym\", \"library\")\n\nfor (poi_t in poi_types) {\n  poi2type(poi, poi_t)\n}"
  },
  {
    "objectID": "prototypes/THE3.html#accessibility-modelling",
    "href": "prototypes/THE3.html#accessibility-modelling",
    "title": "Take-Home Exercise 3",
    "section": "Accessibility Modelling",
    "text": "Accessibility Modelling\nData preparation formed the larger part of this entire process. To save precious exectuion time in the final application, which may face resource constraints, we will load pre-prepared data during runtime.\n\ngrid &lt;- read_rds('data/rds/grid_500_hexagon_sz.rds')\npoints &lt;- read_rds('data/rds/supermarkets.rds') %&gt;%\n  mutate(capacity = 500)\n\nThe accessibility method requires the following parameters\n\nMethod\n\nSAM, Hansen, KD2SFCA\n\nDemands\n\nA vector with the demand of every grid. These have been previously allocated according to population densities.\n\nCapacities\n\nA vector with the capacity of every facility. This may be uniform, if a variable corresponding to the capacity of each facility is not recorded in the dataset.\n\nDistance Matrix\n\nThe distance matrix derived by taking the euclidean distances from each grid to each facility.\n\n\n\nDistance Matrix Calculation\nAlthough the distance matrices used in our application are based on euclidean distances, euclidean distances are not sufficient for accessibility modelling. For example, a walking distance of 200m is more than twice as difficult or unlikely than a 100m walk. As such, to model the difficulty of travel scaling exponentially with distance, the values of the distance matrix have been modified with a function inspired by the exponential decay function.\nGiven a matrix of euclidean distances \\(D\\), where each element can be referred to as \\(d_{ij}\\),\na modified distance matrix \\(D'\\), where each element is referred to as \\(d'_{ij}\\),\nand an exponent \\(a\\),\n\\(d'_{ij} = exp(d_{ij} / 1000 * a)\\)\nIn this system, \\(a\\) can be increased to reflect increasing difficulty of travel.\n\nx &lt;- seq(0, 5, length.out = 100)\n\nplot(x, exp(2 * x), type = \"l\", col = \"blue\", lwd = 2, xlab = \"x\", ylab = \"y\",\n     main = \"Graph of Different Exponential Distance Functions\")\n\nlines(x, exp(2.5 * x), col = \"yellow\", lwd = 2)\nlines(x, exp(1.5 * x), col = \"red\", lwd = 2)\nlines(x, exp(1 * x), col = \"green\", lwd = 2)\n\nlegend(\"topleft\", legend = c(\"y = exp(2x)\", \"y = exp(1.5x)\", \"y = exp(1x)\", \"y = exp(2.5x)\"),\n       col = c(\"blue\", \"red\", \"green\", \"yellow\"), lty = 1, lwd = 2)\n\ngrid()\n\n\n\n\n\n\n\n\nUsing this function and adjusting the exponent is important. For example, if the difficulty of travel is too low, i.e it does not increase enough over distance, accessibility will instead inversely correlate more to the number of other people in the grid competing for the closest facilities.\n\nHansen MethodKD2SFCA MethodSAM Method\n\n\n\n\nShow the code\nexponent &lt;- 2\nmethod &lt;- \"Hansen\"\n\ncentroid.coords &lt;- st_coordinates(st_centroid(grid))\npoints.coords &lt;- st_coordinates(points)\n\ndm &lt;- exp(distance(centroid.coords, points.coords, type = \"euclidean\") / 1000 * exponent)\n\nacc &lt;- data.frame(ac(grid$demand,\n                          points$capacity,\n                          dm, \n                          power = 2, \n                          family = method))\n\ncolnames(acc) &lt;- \"acc\"\nhexagon &lt;- bind_cols(grid, as_tibble(acc))\nhexagon$acc[is.infinite(hexagon$acc)] &lt;- NA\n\nmapex &lt;- st_bbox(grid)\n\n\n\n\nShow the code\n  tm_shape(grid) + \n  tm_polygons() +\n  tm_shape(hexagon,\n           bbox = mapex) + \n    tm_fill(col = \"acc\",\n            n = 5,\n            style = \"quantile\",\n            border.col = \"black\",\n            border.lwd = 1,\n            na.rm = TRUE) +\n  tm_shape(points) +\n    tm_symbols(size = 0.1) +\n    tm_layout(main.title = paste(\"Accessibility to supermarkets: Hansen method\", sep=\"\"),\n              main.title.position = \"center\",\n              main.title.size = 1,\n              legend.outside = FALSE,\n              legend.height = 0.45, \n              legend.width = 3.0,\n              legend.format = list(digits = 6),\n              legend.position = c(\"right\", \"top\"),\n              frame = TRUE) +\n    tm_compass(type=\"8star\", size = 2) +\n    tm_scale_bar(width = 0.15) +\n    tm_grid(lwd = 0.1, alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nexponent &lt;- 2\nmethod &lt;- \"KD2SFCA\"\n\ncentroid.coords &lt;- st_coordinates(st_centroid(grid))\npoints.coords &lt;- st_coordinates(points)\n\ndm &lt;- exp(distance(centroid.coords, points.coords, type = \"euclidean\") / 1000 * exponent)\n\nacc &lt;- data.frame(ac(grid$demand,\n                          points$capacity,\n                          dm, \n                          d0 = 250,\n                          power = 2, \n                          family = method))\n\ncolnames(acc) &lt;- \"acc\"\nhexagon &lt;- bind_cols(grid, as_tibble(acc))\nhexagon$acc[is.infinite(hexagon$acc)] &lt;- NA\n\nmapex &lt;- st_bbox(grid)\n\n\n\n\nShow the code\n  tm_shape(grid) + \n  tm_polygons() +\n  tm_shape(hexagon,\n           bbox = mapex) + \n    tm_fill(col = \"acc\",\n            n = 5,\n            style = \"quantile\",\n            border.col = \"black\",\n            border.lwd = 1,\n            na.rm = TRUE) +\n  tm_shape(points) +\n    tm_symbols(size = 0.1) +\n    tm_layout(main.title = paste(\"Accessibility to supermarkets: KD2FCSA method\", sep=\"\"),\n              main.title.position = \"center\",\n              main.title.size = 2,\n              legend.outside = FALSE,\n              legend.height = 0.45, \n              legend.width = 3.0,\n              legend.format = list(digits = 6),\n              legend.position = c(\"right\", \"top\"),\n              frame = TRUE) +\n    tm_compass(type=\"8star\", size = 2) +\n    tm_scale_bar(width = 0.15) +\n    tm_grid(lwd = 0.1, alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nThe result of the SAM method appears to be somewhat unintuitive and unlike “heatmaps” or KDE-like visualisations.\nSome areas in with lower populations show a higher accessibility to facilities than the more populous areas. This is explainable, as the spatial accessibility measures account for demand as well as capacity. Low demand with similarly capacity would imply much higher accessiblity.\nConversely, for an area with a high population and demand but small capacity, the euclidean distance to the facility may be small but the accessibility result will be low.\n\n\nShow the code\nexponent &lt;- 2\nmethod &lt;- \"SAM\"\n\ncentroid.coords &lt;- st_coordinates(st_centroid(grid))\npoints.coords &lt;- st_coordinates(points)\n\ndm &lt;- exp(distance(centroid.coords, points.coords, type = \"euclidean\") / 1000 * exponent)\n\nacc &lt;- data.frame(ac(grid$demand,\n                          points$capacity,\n                          dm, \n                          d0 = 250,\n                          power = 2, \n                          family = method))\n\ncolnames(acc) &lt;- \"acc\"\nhexagon &lt;- bind_cols(grid, as_tibble(acc))\nhexagon$acc[is.infinite(hexagon$acc)] &lt;- NA\n\nmapex &lt;- st_bbox(grid)\n\n\n\n\nShow the code\n  tm_shape(hexagon,\n           bbox = mapex) + \n    tm_fill(col = \"acc\",\n            n = 5,\n            style = \"quantile\",\n            border.col = \"black\",\n            border.lwd = 1,\n            na.rm = TRUE) +\n  tm_shape(points) +\n    tm_symbols(size = 0.1) +\n    tm_layout(main.title = paste(\"Accessibility to supermarkets: SAM method\", sep=\"\"),\n              main.title.position = \"center\",\n              main.title.size = 2,\n              legend.outside = FALSE,\n              legend.height = 0.45, \n              legend.width = 3.0,\n              legend.format = list(digits = 6),\n              legend.position = c(\"right\", \"top\"),\n              frame = TRUE) +\n    tm_compass(type=\"8star\", size = 2) +\n    tm_scale_bar(width = 0.15) +\n    tm_grid(lwd = 0.1, alpha = 0.5)"
  },
  {
    "objectID": "prototypes/THE3.html#all-in-one-for-shiny",
    "href": "prototypes/THE3.html#all-in-one-for-shiny",
    "title": "Take-Home Exercise 3",
    "section": "All-In One For Shiny",
    "text": "All-In One For Shiny\nTo prepare our code for deployment with Shiny, we have compiled the following functions and variables, which will use some pre-prepared files to speed up computation.\n\nMapping to files\nI have used a map to easily manage variable names and file names.\n\nname2file &lt;- new.env(hash=T, parent=emptyenv())\n\nname2file[[\"markets and food centres\"]] &lt;- \"markets_and_food_centres.rds\"\nname2file[[\"mrt\"]] &lt;- \"mrt.rds\"\n\nname2file[[\"atm\"]] &lt;- \"poi_atm.rds\"\nname2file[[\"bank\"]] &lt;- \"poi_bank.rds\"\nname2file[[\"beauty salon\"]] &lt;- \"poi_beauty_salon.rds\"\nname2file[[\"cafe\"]] &lt;- \"poi_cafe.rds\"\nname2file[[\"clothing store\"]] &lt;- \"poi_clothing_store.rds\"\nname2file[[\"convenience\"]] &lt;- \"poi_convenience_store.rds\"\nname2file[[\"dentist\"]] &lt;- \"poi_dentist.rds\"\nname2file[[\"doctor\"]] &lt;- \"poi_doctor.rds\"\nname2file[[\"gym\"]] &lt;- \"poi_gym.rds\"\nname2file[[\"hospital\"]] &lt;- \"poi_hospital.rds\"\nname2file[[\"library\"]] &lt;- \"poi_library.rds\"\nname2file[[\"lodging\"]] &lt;- \"poi_lodging.rds\"\nname2file[[\"pow\"]] &lt;- \"poi_place_of_worship.rds\"\nname2file[[\"restaurant\"]] &lt;- \"poi_restaurant.rds\"\nname2file[[\"school\"]] &lt;- \"poi_school.rds\"\nname2file[[\"tourist\"]] &lt;- \"poi_tourist_attraction.rds\"\n\nname2file[[\"supermarkets\"]] &lt;- \"supermarkets.rds\"\nname2file[[\"bus\"]] &lt;- \"osm_sg.rds\"\n\n\nAccessibility Modelling Function for Shiny\nFor deployment on Shiny, I have combined all of the relevant functions into one function accepting all of the relevant parameters for easy deploymento on Shiny.\nTo combine the visualisations of maps and histograms, I use cowplot, inspired in the following method.\nhttps://stackoverflow.com/questions/66659389/combine-tmap-and-ggplot\n\n\nShow the code\nplot_acc &lt;- function(method, quantiles, grid_size, point_type, exponent, subz) {\n  grid &lt;- read_rds(paste('data/rds/grid_', grid_size, '_hexagon', ifelse(subz, '_sz', '_pa'),'.rds', sep=\"\"))\n  \n  points &lt;- read_rds(paste('data/rds/', name2file[[point_type]], sep=\"\")) %&gt;%\n    mutate(capacity = 500)\n  \n  centroid.coords &lt;- st_coordinates(st_centroid(grid))\n  points.coords &lt;- st_coordinates(points)\n\n  dm &lt;- exp(distance(centroid.coords, points.coords, type = \"euclidean\") / 1000 * exponent)\n\n  \n\n  acc &lt;- data.frame(ac(grid$demand,\n                            points$capacity,\n                            dm, \n                            d0 = 250,\n                            power = 2, \n                            family = method))\n  \n  colnames(acc) &lt;- \"acc\"\n  hexagon &lt;- bind_cols(grid, as_tibble(acc))\n  hexagon$acc[is.infinite(hexagon$acc)] &lt;- NA\n  \n  mapex &lt;- st_bbox(grid)\n\n  tm &lt;- tm_shape(grid) + \n  tm_polygons() +\n  tm_shape(hexagon,\n           bbox = mapex) + \n    tm_fill(col = \"acc\",\n            n = quantiles,\n            style = \"quantile\",\n            border.col = \"black\",\n            border.lwd = 1,\n            na.rm = TRUE) +\n  tm_shape(points) +\n    tm_symbols(size = 0.1) +\n    tm_layout(main.title = paste(\"Accessibility to \", point_type, \": \", method,\" method\", sep=\"\"),\n              main.title.position = \"center\",\n              main.title.size = 1,\n              legend.outside = FALSE,\n              legend.height = 0.5, \n              legend.width = 0.5,\n              legend.format = list(digits = 3),\n              legend.position = c(\"right\", \"top\"),\n              frame = FALSE) +\n    tm_compass(type=\"8star\", size = 2) +\n    tm_scale_bar(width = 0.20) +\n    tm_grid(lwd = 0.1, alpha = 0.5)\n  \n  hexagon_acc &lt;- st_join(hexagon, read_rds('data/rds/mpsz.rds') , join = st_intersects)\n  \n  region_bxp &lt;- ggplot(data=hexagon_acc, \n       aes(y = acc, \n           x = REGION_N)) +\n  geom_boxplot(outliers = FALSE) +\n  geom_point(stat=\"summary\", \n             fun.y=\"mean\", \n             colour =\"red\", \n             size=2)\n  \n  plot_grid(tmap_grob(tm), region_bxp, nrow = 2, rel_heights = c(2, 1))\n}\n\n\n\n\nExample Invocation\nThe method above accepts the following parameters:\n\nMethod:\n\nWhich accessibility modelling family to use, e.g. SAM, Hansen\n\nQuantiles\n\nNumber of quantiles to generate in the resulting tmap\n\nGrid Size\n\n250m, 500m, or 1km. Size of each grid polygon\n\nExponent\n\nExponent for the exponential distance decay function\n\nSubzone\n\nWhether to visualise based on subzone or planning area populations\n\n\nThe result is a map with accessibility and barplots of accessibility in each region, i.e. central, east, north, north-east and west\n\nplot_acc(\"Hansen\", 10, 500, \"supermarkets\", 2, TRUE)"
  },
  {
    "objectID": "prototypes/THE3.html#prototype-shiny-view",
    "href": "prototypes/THE3.html#prototype-shiny-view",
    "title": "Take-Home Exercise 3",
    "section": "Prototype Shiny View",
    "text": "Prototype Shiny View\nDisclaimer:\nThe colour scheme, fonts, and everything that would be part of a css file have been created by my teammate.\nHowever, the elements within this view and their layouts have been created by me.\n\nPrototype View\nThe modifiable parameters within this prototype corresponds to the parameters used in the unified R function shown in the accessibility modelling section. More may be added as deemed necessary later during development."
  },
  {
    "objectID": "prototypes/Accessibility Prototype.html",
    "href": "prototypes/Accessibility Prototype.html",
    "title": "Accessibility Prototype",
    "section": "",
    "text": "Update: The prototype has been deployed on https://matthewhosmu.shinyapps.io/G1T7-WhatTown/"
  },
  {
    "objectID": "prototypes/Accessibility Prototype.html#overview-and-objectives",
    "href": "prototypes/Accessibility Prototype.html#overview-and-objectives",
    "title": "Accessibility Prototype",
    "section": "Overview and Objectives",
    "text": "Overview and Objectives\nIn this takehome exercise, I will be prototyping my accessibility modelling module for the Geospatial Analytics Project.\nThis prototype module aims to\n\nModel the accessibility to various amenities across Singapore\nShow the distributions of accessibility to amenities across regions\nChoose between Hexagonal and Square Grids\nChange the desired grid size\nChoose different distance decay functions\nChoose between Hansen’s, KD2SFCA and SAM accessibility modelling methods"
  },
  {
    "objectID": "prototypes/Accessibility Prototype.html#data-wrangling",
    "href": "prototypes/Accessibility Prototype.html#data-wrangling",
    "title": "Accessibility Prototype",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\nDependencies\nGiven that this application will be deployed on shiny, I tried to reduce the number of packages to only those that are absolutely necessary or provide sufficient value to the project.\n\nTidyverse\n\nIncludes common packages for datascience, particularly ggplot2, tibble and dplyr\n\ntmap\n\nGenerates colorful and easy to use maps to help our users tell the stories that they want to\n\nsf\n\nEssential for handling spatial features\n\nsmoothr\n\nUsed to remove holes and slithers in geometry\n\nSpatialAcc\n\nThe most promiently featured package in this project. SpatialAcc provides a set of spatial accessibility modelling methods.\n\nhash\n\nI use this to make simple key value pairs, which will map shorter parameter names to files. Using the right data structures can make my code simpler and cleaner\n\ncowplot\n\nUsed to combine different types of plots, e.g. tmap and ggplot\n\n\n\npacman::p_load(tidyverse, tmap, sf, smoothr, SpatialAcc, hash, cowplot)\n\n\n\nDatasets\n\n\nSpatial\n\nSupermarkets (2019)\n\nGovernment Data on Supermarkets. This dataset contains the license names of each supermarket, ensuring a certain degree of standardisation and allows us to check the distribution of different supermarket types in Singapore.\n\nMarkets & Food Centres (2023)\n\nGovernment Data on Wet Markets and Food Centres, including Hawker Centres. This dataset contains data on the type and number of stalls in each location.\n\nMaster Plan 2019 Subzones (2019)\n\nGeospatial data consisting of Singapore’s planning areas, subzones, and boundaries. This dataset will be used to define the boundaries of singapore and its subregions and mapped to the data in the population census.\n\nLand & Transport Singapore (LTSG) dataset (2022)\n\nAn extensive dataset containing the locations of various points of interest around Singapore. For this dataset, only points relevant to daily life for the average person will be considered.\n\n\n\n\nAspatial\n\nSingapore Census of Population (2020)\n\nPopulation of various neighbourhoods and the distribution of age groups within. The distribution of age groups will not be used in this segment. Only the total population will be considered for each region.\n\n\n\n\nMaster Plan Subzone Dataset\nThe master plan subzone dataset contains Singapore’s geometry and the boundaries of each planning zone and subzone. These correspond with other aspatial datasets such as the population census.\nTo prepare the MPSZ dataset, several steps are taken\n\nParse the kml fields\nRemove the z coordinate\nFix the CRS\nFix invalid geometry\nWrite it to an rds file\n\n\nmpsz &lt;- st_read(\"data/geospatial/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\") %&gt;% \n  mutate(Match=str_match_all(Description,\"&lt;td&gt;(.*?)&lt;/td&gt;\")) %&gt;% \n  mutate(Match=map(Match, ~ .[,2])) %&gt;% \n  mutate(Match=map(Match,setNames,c(\"SUBZONE_NO\",\"SUBZONE_N\",\"SUBZONE_C\", \"CA_IND\", \"PLN_AREA_N\", \"PLN_AREA_C\", \"REGION_N\", \"REGION_C\", \"INC_CRC\", \"FMEL_UPD_D\"))) %&gt;% \n  unnest_wider(Match) %&gt;%\n  st_as_sf() %&gt;% dplyr::select('Name', 'geometry', 'SUBZONE_NO', 'SUBZONE_N', 'PLN_AREA_N', 'PLN_AREA_C', 'REGION_N', 'REGION_C') %&gt;% \n  st_zm() %&gt;%\n  st_transform(crs = 3414) %&gt;%\n  st_make_valid() %&gt;%\n  write_rds('data/rds/mpsz.rds')\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `/Users/matthewho/Work/Y3S2/IS415/Project/G1T7-GAA/prototypes/data/geospatial/MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nAfter parsing the mpsz dataset, we can now combine it with the population census of 2020 dataset.\nDisclaimer:\nThe Population Census dataset, referred to as pop2020 in this take home exercise was created by my teammate during the data wrangling process for our project. All data wrangling mentioned in this take-home exercise is my original work. Data that was not wrangled by me will be marked and imported as an rds.\n\n\nPopulation Census Dataset Integration\nIn some accessibility modelling works, demand is naively and uniformly allocated across the relevant geometry, i.e allocating a constant demand over each part of the study area. This would cause the result to be similar to Kernel Density Estimation.\nTo avoid this issue, and to go beyond naive demand estimation, I have decided to allocate ‘demand’ to each subzone or planning area according to the record population of the area in the population census dataset.\nThis will be done by mapping the population estimations of the census to the corresponding polygons in the mpsz dataset. This will be conducted on two levels of granularity.\n\nSubzones\nPlanning Areas\n\nTo incorporate a demand estimation into accessibility modelling, I determine a population density estimate for every polygon.\n\nPlanning Area LevelSubzone Level\n\n\nTo prepare the dataset at the planning area level, we can - Extract the total population from the “Total” row, converted to a numerical value - Accumulate the collective populations and sub-polygons of every planning area\n\nMerge the mpsz and population datasets based on planning area names\nDerive a population density estimate, divide the population of the area by the area\n\n\npop2020_pa &lt;- read_rds('data/rds/pop2020.rds') %&gt;%\n  mutate(Total = as.numeric(Total)) %&gt;%\n  group_by(Planning_Area) %&gt;%\n  summarise(Total = sum(Total), .groups = \"drop\")\n\nmpsz_pa &lt;- mpsz %&gt;%\n  group_by(PLN_AREA_N) %&gt;%\n  summarise(geometry = st_union(geometry), .groups = \"drop\") %&gt;% \n  merge(pop2020_pa, by.x=\"PLN_AREA_N\", by.y=\"Planning_Area\") %&gt;% \n  mutate(Total = as.numeric(Total),\n           area = st_area(geometry), \n           pop_dens = Total / area)\n\nmpsz_pa$area &lt;- st_area(mpsz_pa$geometry)\nmpsz_pa$pop_dens &lt;- mpsz_pa$Total / mpsz_pa$area\n\nwrite_rds(mpsz_pa, 'data/rds/mpsz_pa.rds')\n\n\n\n\nThis process is similar to the aforementioned planning area population census integration.\n\n\npop2020_sz &lt;- read_rds('data/rds/pop2020.rds') %&gt;%\n  mutate(Total = as.numeric(Total)) %&gt;%\n  group_by(Subzone) %&gt;%\n  summarise(Total = sum(Total), .groups = \"drop\")\n\nmpsz_sz &lt;- mpsz %&gt;%\n  group_by(SUBZONE_N) %&gt;%\n  summarise(geometry = st_union(geometry), .groups = \"drop\") %&gt;% \n  merge(pop2020_sz, by.x=\"SUBZONE_N\", by.y=\"Subzone\") %&gt;% \n  mutate(Total = as.numeric(Total),\n           area = st_area(geometry), \n           pop_dens = Total / area)\n\nmpsz_sz$area &lt;- st_area(mpsz_sz$geometry)\nmpsz_sz$pop_dens &lt;- mpsz_sz$Total / mpsz_sz$area\n\nwrite_rds(mpsz_sz, 'data/rds/mpsz_sz.rds')\n\n\n\n\n\n\nGetting Mainland Singapore\nGiven that the outer islands are not relevant to accessibility, since traversing water is significantly different from land travel. The population of these island is also low enough that they are unlikely to affect the results of our modelling process.\nReference: Matt’s TakeHome Exercise 1\n\nmainland_sg &lt;- st_union(mpsz_pa) %&gt;%\n    st_cast(\"POLYGON\")\n\nmainland_sg &lt;- mainland_sg[c(15)] %&gt;% \n  fill_holes(units::set_units(1, \"km^2\")) %&gt;%\n  st_as_sf() %&gt;%\n  write_rds('data/rds/mainland_sg.rds')\n\nplot(mainland_sg)"
  },
  {
    "objectID": "prototypes/Accessibility Prototype.html#grid-generation-process",
    "href": "prototypes/Accessibility Prototype.html#grid-generation-process",
    "title": "Accessibility Prototype",
    "section": "Grid Generation Process",
    "text": "Grid Generation Process\nThe accessibility modelling process requires a grid. This grids segment the relevant study area into polygons of various sizes, typically hexagons or squares. Hexagons have the added benefit of supporting diagonal adjacency.\nFor the project module, I would like to provide grid options such as size and shape of the grid. Since the grid generation process is relatively unchanging but time consuming, the grids will be pre-calculated with several parameters and combined with other dynamic elements at runtime.\nThe follow functions have been written with the project module in mind. This section will discuss the design of each of these functions before a technical demonstration of these functions.\n\nFunction to add “demand”\nA grid polygon, such as a square or hexagon, may overlap the singaporean mainland partially or overlap multiple sub-areas at once. Based on the concept of population density, a grid with a partial overlap with a subzone or planning area should have a lower population estimation than a grid with a full overlap. A grid’s population should also be a function of the populations of every zone it overlaps as well.\nTherefore, I have designed the following functions to allocate density to each grid polygon.\nGiven the set of \\(n\\) grid polygons \\(G = \\{g_0, g_1, ..., g_n\\}\\), and set of \\(m\\) subzone or planning areas \\(Z = \\{z_0, z_1, ..., z_m\\}\\).\nThe population of a grid \\(g_i\\) is given as \\(Pop(g_i)\\), The density of a subzone or planning area \\(z_i\\) is given as \\(Dens(z_i)\\) The area of the intersection between a grid \\(g_i\\) and subzone or planning area \\(z_i\\) is given as \\(AreaInt(g_i, z_i)\\)\n\\(Pop(g_i) = \\sum^m_{j=0} AreaInt(g_i, z_j) * Dens(z_j) \\quad \\forall g_i \\in G\\)\nThis function can be compared to a weighted mean of populations, weighted by intersection area and is implemented below.\nThe result is a grid with a field ‘demand’ corresponding to the result of this function.\n\nadd_weights &lt;- function(grids, pop) {\n  joined &lt;- st_join(grids, pop, join = st_intersects)  %&gt;%\n    mutate(intersect_area = st_area(x),\n           demand = intersect_area * pop_dens) %&gt;%\n    st_drop_geometry()\n  \n  grids &lt;- grids %&gt;%\n    left_join(joined %&gt;%\n                group_by(ID) %&gt;%\n                summarise(total_demand = sum(demand)),\n              by = \"ID\") %&gt;%\n    mutate(demand = ifelse(is.na(total_demand), 0, total_demand)) %&gt;%\n    select(-total_demand)\n}\n\n\n\nMake a grid over mainland Singapore\nThis function generates a grid over the bounding box of mainland Singapore. However, most of the bounding box covers irrelevant areas, or the ocean. We reduce the grid, and cut grid polygons to fit the outline of mainland Singapore.\nReferences: https://r-spatial.github.io/sf/reference/st_make_grid.html\n\nsg_2_grid &lt;- function(sg, g_size, is_square, name, pop) {\n  grids &lt;- st_make_grid(sg, cellsize = g_size, square = is_square) %&gt;%\n  st_intersection(mainland_sg) %&gt;%\n  st_as_sf() %&gt;%\n    mutate(demand = 0, ID = row_number())\n  \n  grids_w_demand &lt;- add_weights(grids, pop) %&gt;%\n  rename(geometry = x)\n  \n  write_rds(grids_w_demand, paste(name, '.rds', sep = \"\"))\n  \n  return(grids_w_demand)\n}\n\n\n\nGenerate the grids and distance matrices\nThis wrapper function called the aforementioned functions to generate grids of different sizes and shapes and saves them as rds files to be loaded at runtime.\nReferences: https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/dist https://www.rdocumentation.org/packages/geosphere/versions/1.5-18/topics/centroid\n\ngrids_and_dist_matrices &lt;- function(sg, pop, g_size, is_square, subz) {\n  name &lt;- paste('data/rds/grid_', g_size, ifelse(is_square, \"_square\", \"_hexagon\"), ifelse(subz, \"_sz\", \"_pa\"), sep = \"\")\n  grid &lt;- sg_2_grid(sg, g_size, is_square, name, pop)\n  return(grid)\n}\n\n\n\nWriting the grids with population as demand\nMultiple grids of varying sizes and shapes weighted by subzone or planning area populations can be easily generated by calling the functions as done below.\n\nfor(di in c(250, 500, 750, 1000)) {\n  grids_and_dist_matrices(mainland_sg, mpsz_sz, di, FALSE, TRUE)\n  grids_and_dist_matrices(mainland_sg, mpsz_sz, di, TRUE, TRUE)\n  grids_and_dist_matrices(mainland_sg, mpsz_pa, di, FALSE, FALSE)\n  grids_and_dist_matrices(mainland_sg, mpsz_pa, di, TRUE, FALSE)\n}\n\n\n\nFunctional Demo\nIn this functional demo, each function and its code have been called sequentially to illustrate the flow of how the data wrangling results in useful information.\n\ndemo &lt;- grids_and_dist_matrices(mainland_sg, mpsz_sz, 500, FALSE, TRUE)\n\ntm_shape(demo) + \n  tm_fill(col='demand',\n            n = 7,\n            style = \"quantile\",\n            border.col = \"black\",\n            border.lwd = 1,\n            na.rm = TRUE)"
  },
  {
    "objectID": "prototypes/Accessibility Prototype.html#step-by-step-demo",
    "href": "prototypes/Accessibility Prototype.html#step-by-step-demo",
    "title": "Accessibility Prototype",
    "section": "Step by Step Demo",
    "text": "Step by Step Demo\n\nGenerating the grid\nObserve that the results of st_make_grid create a grid over the entire bounding box of the study area.\n\ngrids &lt;- st_make_grid(mainland_sg, cellsize = 500, square = FALSE)\nplot(grids)\n\n\n\n\n\n\n\n\nAfter using st_intersection to remove irrelvant hexagons and trim hexagons to fit the countours of mainland Singapore, we introduce the demand parameter to each hexagon. Each hexagon is also assigned a numerical identifier to make joining processes later easier. At this state, the demand is uniformly 0 since the population of each area has not been accounted for yet.\n\n\nTrimming the Grid\n\ngrids &lt;- grids %&gt;%\nst_intersection(mainland_sg) %&gt;%\nst_as_sf() %&gt;%\n  mutate(demand = 0, ID = row_number())\n\ntm_shape(grids) + \n  tm_polygons(col='demand',\n            n = 7,\n            style = \"quantile\",\n            border.col = \"black\",\n            border.lwd = 1,\n            na.rm = TRUE)\n\n\n\n\n\n\n\n\n\n\nSingapore’s Population Density\nThe population of Singapore can be seen to vary greatly throughout areas. For example, the central catchment area is unsurprisingly empty, while residential areas in the West, North and East contain most of Singapore’s population.\n\ntm_shape(mpsz_sz) + \n  tm_polygons(col='Total',\n            n = 7,\n            style = \"quantile\",\n            border.col = \"black\",\n            border.lwd = 1,\n            na.rm = TRUE)\n\n\n\n\n\n\n\n\n\n\nCombining the Grid and Population Data\nSimilar to the code above, we allocate population estimates to each grid. This grid can be used for accessibility modelling methods.\n\ngrids_on_sz &lt;- st_join(grids, mpsz_sz, join = st_intersects)  %&gt;%\n  mutate(intersect_area = st_area(x),\n         demand = intersect_area * pop_dens) %&gt;%\n  st_drop_geometry()\n\ngrids &lt;- grids %&gt;%\n  left_join(grids_on_sz %&gt;%\n              group_by(ID) %&gt;%\n              summarise(total_demand = sum(demand)),\n            by = \"ID\") %&gt;%\n  mutate(demand = ifelse(is.na(total_demand), 0, total_demand)) %&gt;%\n  select(-total_demand) %&gt;%\nrename(geometry = x)\n\ntm_shape(grids) + \n  tm_polygons(col='demand',\n            n = 7,\n            style = \"quantile\",\n            border.col = \"black\",\n            na.rm = TRUE)\n\n\n\n\n\n\n\n\n\n\nHandling Points\nTo model the locations of amenities such as supermarkets, we need each amenity to be represented as a data point. As data regarding the size, or capacity of each facility is hard to come by, some types of amenities can have a fixed capacity.\nFor markets and food centres, data includes the number of stalls, which could correlate with size and capacity.\nIn this section, each dataset of point data is wrangled and the relevant columns extracted.\n\nSupermarketsMarkets and Food CentresMRTOther POIs\n\n\nSupermarket data processing includes the following steps:\n\nParse the KML data\nExtract the relevant rows\nMake valid, remove z coordinate, change CRS\nRemove invalid points\n\n\nsupermarkets &lt;- st_read(\"data/geospatial/SupermarketsKML.kml\") %&gt;% \n  mutate(Match=str_match_all(Description,\"&lt;td&gt;(.*?)&lt;/td&gt;\")) %&gt;% \n  mutate(Match=map(Match, ~ .[,2])) %&gt;% \n  mutate(Match=map(Match,setNames,c(\"LIC_NAME\", \"BLK_HOUSE\", \"STR_NAME\", \"UNIT_NO\", \"POSTCODE\", \"LIC_NO\", \"INC_CRC\", \"FMEL_UPD_D\"))) %&gt;% \n  unnest_wider(Match) %&gt;%\n  st_as_sf() %&gt;% \n  dplyr::select('LIC_NAME', 'geometry') %&gt;% \n  st_make_valid() %&gt;%\n  st_zm() %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `SUPERMARKETS' from data source \n  `/Users/matthewho/Work/Y3S2/IS415/Project/G1T7-GAA/prototypes/data/geospatial/SupermarketsKML.kml' \n  using driver `KML'\nSimple feature collection with 526 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6258 ymin: 1.24715 xmax: 104.0036 ymax: 1.461526\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\nsupermarkets &lt;- st_intersection(supermarkets, mainland_sg)\n\nCheck for NA values\n\nany(is.na(supermarkets))\n\n[1] FALSE\n\n\nCategorise supermarkets by major brand. Since the name of each supermarket is determined by the license, we can expect that small variations will not affect this method.\n\nsupermarkets$SUBTYPE &lt;- ifelse(grepl(\"FAIRPRICE\", supermarkets$LIC_NAME, ignore.case = TRUE), \"FAIRPRICE\",\n                     ifelse(grepl(\"COLD STORAGE\", supermarkets$LIC_NAME, ignore.case = TRUE), \"COLD STORAGE\",\n                            ifelse(grepl(\"SHENG SIONG\", supermarkets$LIC_NAME, ignore.case = TRUE), \"SHENG SIONG\", \"OTHER\")))\n\nwrite_rds(supermarkets, 'data/rds/supermarkets.rds')\n\nPlot of the supermarkets across Singapore\n\ntm_shape(mainland_sg) + \n  tm_polygons() + \n  tm_shape(supermarkets) + \n  tm_dots(col = \"SUBTYPE\", size = 0.05)\n\n\n\n\n\n\n\n\n\n\nMarkets and Food Centre geometry have been processed similarly to the supermarkets dataset, except that the TOTAL_STALLS parameter has been included to reflect the capacity of each facility.\n\nmarketandfc &lt;- st_read(\"data/geospatial/NEAMarketandFoodCentreKML.kml\") %&gt;% \n  mutate(Match=str_match_all(Description,\"&lt;td&gt;(.*?)&lt;/td&gt;\")) %&gt;% \n  mutate(Match=map(Match, ~ .[,2])) %&gt;% \n  mutate(Match=map(Match,setNames,c(\"TOTAL_STALLS\", \"MP_STALLS\", \"CF_STALLS\", \"POSTAL_CODE\", \"OWNER\", \"TYPE\", \"LOCATION_CENTRE\", \"NAME_OF_CENTRE\", \"INC_CRC\", \"FMEL_UP_D\"))) %&gt;% \n  unnest_wider(Match) %&gt;%\n  st_as_sf() %&gt;% dplyr::select(\"NAME_OF_CENTRE\", \"TYPE\", \"TOTAL_STALLS\", \"geometry\") %&gt;% \n  st_make_valid() %&gt;%\n  st_zm() %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MARKET_FOOD_CENTRE' from data source \n  `/Users/matthewho/Work/Y3S2/IS415/Project/G1T7-GAA/prototypes/data/geospatial/NEAMarketandFoodCentreKML.kml' \n  using driver `KML'\nSimple feature collection with 110 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.7105 ymin: 1.272589 xmax: 103.9882 ymax: 1.443405\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nCheck for NA values\n\nany(is.na(marketandfc))\n\n[1] FALSE\n\n\nAllocating a simpler type variable to each facility, similar to the supermarkets\n\nmarketandfc$SUBTYPE &lt;- ifelse(marketandfc$TYPE == \"HC\", \"HAWKER_CENTRE\",\n                  ifelse(marketandfc$TYPE == \"MHC\", \"MARKET_AND_HAWKER\",\n                         ifelse(marketandfc$TYPE == \"MK\", \"MARKET\", NA)))\nmarketandfc &lt;- subset(marketandfc, select = -TYPE)\n\nmarketandfc$TOTAL_STALLS &lt;- as.numeric(marketandfc$TOTAL_STALLS)\n\nwrite_rds(marketandfc, 'data/rds/markets_and_food_centres.rds')\n\n\ntm_shape(mainland_sg) + \n  tm_polygons() + \ntm_shape(marketandfc) + \n  tm_dots(col = \"SUBTYPE\", group = \"SUBTYPE\", size = \"TOTAL_STALLS\")\n\n\n\n\n\n\n\n\n\n\nMRT stations have been processed simply, without any additional parameters. This is because the entire MRT system is somewhat interconnected and station capacity does not often causes bottlenecks as much as the capacity of the trains.\n\nmrt &lt;- read.csv('data/aspatial/mrt.csv') %&gt;%\n  st_as_sf(coords = c(\"lng\", \"lat\"),\n                      crs = 4326) %&gt;%\n  st_transform(crs = 3414) %&gt;%\n  dplyr::select('name', 'geometry')\n\nwrite_rds(mrt, 'data/rds/mrt.rds')\n\n\nany(is.na(mrt))\n\n[1] FALSE\n\n\n\ntm_shape(mainland_sg) + \n  tm_polygons() + \ntm_shape(mrt) + \n  tm_dots(col = \"red\")\n\n\n\n\n\n\n\n\n\n\nWe found a large dataset consisting of many points of interest. We have extracted only the points of interest that may play a part in people’s routines. In this section, we choose only the relevant places, extract them, and save them for later use.\n\npoi &lt;- read.csv('data/aspatial/poi.csv') %&gt;%\n  st_as_sf(coords = c(\"lng\", \"lat\"),\n                      crs = 4326) %&gt;%\n  st_transform(crs = 3414)\n\n\npoi2type &lt;- function(pois, typ) {\n  poi &lt;- pois[pois[[typ]] == 'True', ] %&gt;%\n    dplyr::select('name', 'geometry')\n  write_rds(poi, paste('data/rds/poi_', typ, '.rds', sep=\"\"))\n}\n\n\npoi_types &lt;- c(\"restaurant\", \"hospital\", \"lodging\", \"bank\", \"cafe\", \"convenience_store\", \"clothing_store\", \"atm\", \"school\", \"beauty_salon\", \"place_of_worship\", \"tourist_attraction\", \"doctor\", \"dentist\", \"gym\", \"library\")\n\nfor (poi_t in poi_types) {\n  poi2type(poi, poi_t)\n}"
  },
  {
    "objectID": "prototypes/Accessibility Prototype.html#accessibility-modelling",
    "href": "prototypes/Accessibility Prototype.html#accessibility-modelling",
    "title": "Accessibility Prototype",
    "section": "Accessibility Modelling",
    "text": "Accessibility Modelling\nData preparation formed the larger part of this entire process. To save precious exectuion time in the final application, which may face resource constraints, we will load pre-prepared data during runtime.\n\ngrid &lt;- read_rds('data/rds/grid_500_hexagon_sz.rds')\npoints &lt;- read_rds('data/rds/supermarkets.rds') %&gt;%\n  mutate(capacity = 500)\n\nThe accessibility method requires the following parameters\n\nMethod\n\nSAM, Hansen, KD2SFCA\n\nDemands\n\nA vector with the demand of every grid. These have been previously allocated according to population densities.\n\nCapacities\n\nA vector with the capacity of every facility. This may be uniform, if a variable corresponding to the capacity of each facility is not recorded in the dataset.\n\nDistance Matrix\n\nThe distance matrix derived by taking the euclidean distances from each grid to each facility.\n\n\n\nDistance Matrix Calculation\nAlthough the distance matrices used in our application are based on euclidean distances, euclidean distances are not sufficient for accessibility modelling. For example, a walking distance of 200m is more than twice as difficult or unlikely than a 100m walk. As such, to model the difficulty of travel scaling exponentially with distance, the values of the distance matrix have been modified with a function inspired by the exponential decay function.\nGiven a matrix of euclidean distances \\(D\\), where each element can be referred to as \\(d_{ij}\\),\na modified distance matrix \\(D'\\), where each element is referred to as \\(d'_{ij}\\),\nand an exponent \\(a\\),\n\\(d'_{ij} = exp(d_{ij} / 1000 * a)\\)\nIn this system, \\(a\\) can be increased to reflect increasing difficulty of travel.\n\nx &lt;- seq(0, 5, length.out = 100)\n\nplot(x, exp(2 * x), type = \"l\", col = \"blue\", lwd = 2, xlab = \"x\", ylab = \"y\",\n     main = \"Graph of Different Exponential Distance Functions\")\n\nlines(x, exp(2.5 * x), col = \"yellow\", lwd = 2)\nlines(x, exp(1.5 * x), col = \"red\", lwd = 2)\nlines(x, exp(1 * x), col = \"green\", lwd = 2)\n\nlegend(\"topleft\", legend = c(\"y = exp(2x)\", \"y = exp(1.5x)\", \"y = exp(1x)\", \"y = exp(2.5x)\"),\n       col = c(\"blue\", \"red\", \"green\", \"yellow\"), lty = 1, lwd = 2)\n\ngrid()\n\n\n\n\n\n\n\n\nUsing this function and adjusting the exponent is important. For example, if the difficulty of travel is too low, i.e it does not increase enough over distance, accessibility will instead inversely correlate more to the number of other people in the grid competing for the closest facilities.\n\nHansen MethodKD2SFCA MethodSAM Method\n\n\n\n\nShow the code\nexponent &lt;- 2\nmethod &lt;- \"Hansen\"\n\ncentroid.coords &lt;- st_coordinates(st_centroid(grid))\npoints.coords &lt;- st_coordinates(points)\n\ndm &lt;- exp(distance(centroid.coords, points.coords, type = \"euclidean\") / 1000 * exponent)\n\nacc &lt;- data.frame(ac(grid$demand,\n                          points$capacity,\n                          dm, \n                          power = 2, \n                          family = method))\n\ncolnames(acc) &lt;- \"acc\"\nhexagon &lt;- bind_cols(grid, as_tibble(acc))\nhexagon$acc[is.infinite(hexagon$acc)] &lt;- NA\n\nmapex &lt;- st_bbox(grid)\n\n\n\n\nShow the code\n  tm_shape(grid) + \n  tm_polygons() +\n  tm_shape(hexagon,\n           bbox = mapex) + \n    tm_fill(col = \"acc\",\n            n = 5,\n            style = \"quantile\",\n            border.col = \"black\",\n            border.lwd = 1,\n            na.rm = TRUE) +\n  tm_shape(points) +\n    tm_symbols(size = 0.1) +\n    tm_layout(main.title = paste(\"Accessibility to supermarkets: Hansen method\", sep=\"\"),\n              main.title.position = \"center\",\n              main.title.size = 1,\n              legend.outside = FALSE,\n              legend.height = 0.45, \n              legend.width = 3.0,\n              legend.format = list(digits = 6),\n              legend.position = c(\"right\", \"top\"),\n              frame = TRUE) +\n    tm_compass(type=\"8star\", size = 2) +\n    tm_scale_bar(width = 0.15) +\n    tm_grid(lwd = 0.1, alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nexponent &lt;- 2\nmethod &lt;- \"KD2SFCA\"\n\ncentroid.coords &lt;- st_coordinates(st_centroid(grid))\npoints.coords &lt;- st_coordinates(points)\n\ndm &lt;- exp(distance(centroid.coords, points.coords, type = \"euclidean\") / 1000 * exponent)\n\nacc &lt;- data.frame(ac(grid$demand,\n                          points$capacity,\n                          dm, \n                          d0 = 250,\n                          power = 2, \n                          family = method))\n\ncolnames(acc) &lt;- \"acc\"\nhexagon &lt;- bind_cols(grid, as_tibble(acc))\nhexagon$acc[is.infinite(hexagon$acc)] &lt;- NA\n\nmapex &lt;- st_bbox(grid)\n\n\n\n\nShow the code\n  tm_shape(grid) + \n  tm_polygons() +\n  tm_shape(hexagon,\n           bbox = mapex) + \n    tm_fill(col = \"acc\",\n            n = 5,\n            style = \"quantile\",\n            border.col = \"black\",\n            border.lwd = 1,\n            na.rm = TRUE) +\n  tm_shape(points) +\n    tm_symbols(size = 0.1) +\n    tm_layout(main.title = paste(\"Accessibility to supermarkets: KD2FCSA method\", sep=\"\"),\n              main.title.position = \"center\",\n              main.title.size = 2,\n              legend.outside = FALSE,\n              legend.height = 0.45, \n              legend.width = 3.0,\n              legend.format = list(digits = 6),\n              legend.position = c(\"right\", \"top\"),\n              frame = TRUE) +\n    tm_compass(type=\"8star\", size = 2) +\n    tm_scale_bar(width = 0.15) +\n    tm_grid(lwd = 0.1, alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nThe result of the SAM method appears to be somewhat unintuitive and unlike “heatmaps” or KDE-like visualisations.\nSome areas in with lower populations show a higher accessibility to facilities than the more populous areas. This is explainable, as the spatial accessibility measures account for demand as well as capacity. Low demand with similarly capacity would imply much higher accessiblity.\nConversely, for an area with a high population and demand but small capacity, the euclidean distance to the facility may be small but the accessibility result will be low.\n\n\nShow the code\nexponent &lt;- 2\nmethod &lt;- \"SAM\"\n\ncentroid.coords &lt;- st_coordinates(st_centroid(grid))\npoints.coords &lt;- st_coordinates(points)\n\ndm &lt;- exp(distance(centroid.coords, points.coords, type = \"euclidean\") / 1000 * exponent)\n\nacc &lt;- data.frame(ac(grid$demand,\n                          points$capacity,\n                          dm, \n                          d0 = 250,\n                          power = 2, \n                          family = method))\n\ncolnames(acc) &lt;- \"acc\"\nhexagon &lt;- bind_cols(grid, as_tibble(acc))\nhexagon$acc[is.infinite(hexagon$acc)] &lt;- NA\n\nmapex &lt;- st_bbox(grid)\n\n\n\n\nShow the code\n  tm_shape(hexagon,\n           bbox = mapex) + \n    tm_fill(col = \"acc\",\n            n = 5,\n            style = \"quantile\",\n            border.col = \"black\",\n            border.lwd = 1,\n            na.rm = TRUE) +\n  tm_shape(points) +\n    tm_symbols(size = 0.1) +\n    tm_layout(main.title = paste(\"Accessibility to supermarkets: SAM method\", sep=\"\"),\n              main.title.position = \"center\",\n              main.title.size = 2,\n              legend.outside = FALSE,\n              legend.height = 0.45, \n              legend.width = 3.0,\n              legend.format = list(digits = 6),\n              legend.position = c(\"right\", \"top\"),\n              frame = TRUE) +\n    tm_compass(type=\"8star\", size = 2) +\n    tm_scale_bar(width = 0.15) +\n    tm_grid(lwd = 0.1, alpha = 0.5)"
  },
  {
    "objectID": "prototypes/Accessibility Prototype.html#all-in-one-for-shiny",
    "href": "prototypes/Accessibility Prototype.html#all-in-one-for-shiny",
    "title": "Accessibility Prototype",
    "section": "All-In One For Shiny",
    "text": "All-In One For Shiny\nTo prepare our code for deployment with Shiny, we have compiled the following functions and variables, which will use some pre-prepared files to speed up computation.\n\nMapping to files\nI have used a map to easily manage variable names and file names.\n\nname2file &lt;- new.env(hash=T, parent=emptyenv())\n\nname2file[[\"markets and food centres\"]] &lt;- \"markets_and_food_centres.rds\"\nname2file[[\"mrt\"]] &lt;- \"mrt.rds\"\n\nname2file[[\"atm\"]] &lt;- \"poi_atm.rds\"\nname2file[[\"bank\"]] &lt;- \"poi_bank.rds\"\nname2file[[\"beauty salon\"]] &lt;- \"poi_beauty_salon.rds\"\nname2file[[\"cafe\"]] &lt;- \"poi_cafe.rds\"\nname2file[[\"clothing store\"]] &lt;- \"poi_clothing_store.rds\"\nname2file[[\"convenience\"]] &lt;- \"poi_convenience_store.rds\"\nname2file[[\"dentist\"]] &lt;- \"poi_dentist.rds\"\nname2file[[\"doctor\"]] &lt;- \"poi_doctor.rds\"\nname2file[[\"gym\"]] &lt;- \"poi_gym.rds\"\nname2file[[\"hospital\"]] &lt;- \"poi_hospital.rds\"\nname2file[[\"library\"]] &lt;- \"poi_library.rds\"\nname2file[[\"lodging\"]] &lt;- \"poi_lodging.rds\"\nname2file[[\"pow\"]] &lt;- \"poi_place_of_worship.rds\"\nname2file[[\"restaurant\"]] &lt;- \"poi_restaurant.rds\"\nname2file[[\"school\"]] &lt;- \"poi_school.rds\"\nname2file[[\"tourist\"]] &lt;- \"poi_tourist_attraction.rds\"\n\nname2file[[\"supermarkets\"]] &lt;- \"supermarkets.rds\"\nname2file[[\"bus\"]] &lt;- \"osm_sg.rds\"\n\n\nAccessibility Modelling Function for Shiny\nFor deployment on Shiny, I have combined all of the relevant functions into one function accepting all of the relevant parameters for easy deploymento on Shiny.\nTo combine the visualisations of maps and histograms, I use cowplot, inspired in the following method.\nhttps://stackoverflow.com/questions/66659389/combine-tmap-and-ggplot\n\n\nShow the code\nplot_acc &lt;- function(method, quantiles, grid_size, point_type, exponent, subz) {\n  grid &lt;- read_rds(paste('data/rds/grid_', grid_size, '_hexagon', ifelse(subz, '_sz', '_pa'),'.rds', sep=\"\"))\n  \n  points &lt;- read_rds(paste('data/rds/', name2file[[point_type]], sep=\"\")) %&gt;%\n    mutate(capacity = 500)\n  \n  centroid.coords &lt;- st_coordinates(st_centroid(grid))\n  points.coords &lt;- st_coordinates(points)\n\n  dm &lt;- exp(distance(centroid.coords, points.coords, type = \"euclidean\") / 1000 * exponent)\n\n  \n\n  acc &lt;- data.frame(ac(grid$demand,\n                            points$capacity,\n                            dm, \n                            d0 = 250,\n                            power = 2, \n                            family = method))\n  \n  colnames(acc) &lt;- \"acc\"\n  hexagon &lt;- bind_cols(grid, as_tibble(acc))\n  hexagon$acc[is.infinite(hexagon$acc)] &lt;- NA\n  \n  mapex &lt;- st_bbox(grid)\n\n  tm &lt;- tm_shape(grid) + \n  tm_polygons() +\n  tm_shape(hexagon,\n           bbox = mapex) + \n    tm_fill(col = \"acc\",\n            n = quantiles,\n            style = \"quantile\",\n            border.col = \"black\",\n            border.lwd = 1,\n            na.rm = TRUE) +\n  tm_shape(points) +\n    tm_symbols(size = 0.1) +\n    tm_layout(main.title = paste(\"Accessibility to \", point_type, \": \", method,\" method\", sep=\"\"),\n              main.title.position = \"center\",\n              main.title.size = 1,\n              legend.outside = FALSE,\n              legend.height = 0.5, \n              legend.width = 0.5,\n              legend.format = list(digits = 3),\n              legend.position = c(\"right\", \"top\"),\n              frame = FALSE) +\n    tm_compass(type=\"8star\", size = 2) +\n    tm_scale_bar(width = 0.20) +\n    tm_grid(lwd = 0.1, alpha = 0.5)\n  \n  hexagon_acc &lt;- st_join(hexagon, read_rds('data/rds/mpsz.rds') , join = st_intersects)\n  \n  region_bxp &lt;- ggplot(data=hexagon_acc, \n       aes(y = acc, \n           x = REGION_N)) +\n  geom_boxplot(outliers = FALSE) +\n  geom_point(stat=\"summary\", \n             fun.y=\"mean\", \n             colour =\"red\", \n             size=2)\n  \n  plot_grid(tmap_grob(tm), region_bxp, nrow = 2, rel_heights = c(2, 1))\n}\n\n\n\n\nExample Invocation\nThe method above accepts the following parameters:\n\nMethod:\n\nWhich accessibility modelling family to use, e.g. SAM, Hansen\n\nQuantiles\n\nNumber of quantiles to generate in the resulting tmap\n\nGrid Size\n\n250m, 500m, or 1km. Size of each grid polygon\n\nExponent\n\nExponent for the exponential distance decay function\n\nSubzone\n\nWhether to visualise based on subzone or planning area populations\n\n\nThe result is a map with accessibility and barplots of accessibility in each region, i.e. central, east, north, north-east and west\n\nplot_acc(\"Hansen\", 10, 500, \"supermarkets\", 2, TRUE)"
  },
  {
    "objectID": "prototypes/Accessibility Prototype.html#prototype-shiny-view",
    "href": "prototypes/Accessibility Prototype.html#prototype-shiny-view",
    "title": "Accessibility Prototype",
    "section": "Prototype Shiny View",
    "text": "Prototype Shiny View\nDisclaimer:\nThe colour scheme, fonts, and everything that would be part of a css file have been created by my teammate.\nHowever, the elements within this view and their layouts have been created by me.\n\nPrototype View\nThe modifiable parameters within this prototype corresponds to the parameters used in the unified R function shown in the accessibility modelling section. More may be added as deemed necessary later during development."
  },
  {
    "objectID": "prototypes/AccessibilityGeometryWrangling.html",
    "href": "prototypes/AccessibilityGeometryWrangling.html",
    "title": "Accessibility Geometry Wrangling",
    "section": "",
    "text": "This page prepares grids, demand, capacity, etc.\n\npacman::p_load(tidyverse, tmap, sf, dplyr, smoothr)\n\nReference: Matt’s Takehome Exercise 1\n\nmpsz &lt;- st_read(\"../data/geospatial/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\") %&gt;% \n  mutate(Match=str_match_all(Description,\"&lt;td&gt;(.*?)&lt;/td&gt;\")) %&gt;% \n  mutate(Match=map(Match, ~ .[,2])) %&gt;% \n  mutate(Match=map(Match,setNames,c(\"SUBZONE_NO\",\"SUBZONE_N\",\"SUBZONE_C\", \"CA_IND\", \"PLN_AREA_N\", \"PLN_AREA_C\", \"REGION_N\", \"REGION_C\", \"INC_CRC\", \"FMEL_UPD_D\"))) %&gt;% \n  unnest_wider(Match) %&gt;%\n  st_as_sf() %&gt;% dplyr::select('Name', 'geometry', 'SUBZONE_NO', 'SUBZONE_N', 'PLN_AREA_N', 'PLN_AREA_C', 'REGION_N', 'REGION_C') %&gt;% \n  st_make_valid() %&gt;%\n  st_zm() %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `/Users/matthewho/Work/Y3S2/IS415/Project/G1T7-GAA/data/geospatial/MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nwrite_rds(mpsz, '../data/rds/mpsz.rds')\n\n\npops &lt;- read_rds('../data/rds/pop2020.rds')\n\npop2020_pa &lt;- read_rds('../data/rds/pop2020.rds') %&gt;%\n  mutate(Total = as.numeric(Total)) %&gt;%\n  group_by(Planning_Area) %&gt;%\n  summarise(Total = sum(Total), .groups = \"drop\")\n\npop2020_sz &lt;- read_rds('../data/rds/pop2020.rds') %&gt;%\n  mutate(Total = as.numeric(Total)) %&gt;%\n  group_by(Subzone) %&gt;%\n  summarise(Total = sum(Total), .groups = \"drop\")\n\nmpsz_pa &lt;- mpsz %&gt;%\n  group_by(PLN_AREA_N) %&gt;%\n  summarise(geometry = st_union(geometry), .groups = \"drop\") %&gt;% \n  merge(pop2020_pa, by.x=\"PLN_AREA_N\", by.y=\"Planning_Area\") %&gt;% \n  mutate(Total = as.numeric(Total),\n           area = st_area(geometry), \n           pop_dens = Total / area)\n\nmpsz_sz &lt;- mpsz %&gt;%\n  group_by(SUBZONE_N) %&gt;%\n  summarise(geometry = st_union(geometry), .groups = \"drop\") %&gt;% \n  merge(pop2020_sz, by.x=\"SUBZONE_N\", by.y=\"Subzone\") %&gt;% \n  mutate(Total = as.numeric(Total),\n           area = st_area(geometry), \n           pop_dens = Total / area)\n\nmpsz_pa$area &lt;- st_area(mpsz_pa$geometry)\nmpsz_pa$pop_dens &lt;- mpsz_pa$Total / mpsz_pa$area\n\nmpsz_sz$area &lt;- st_area(mpsz_sz$geometry)\nmpsz_sz$pop_dens &lt;- mpsz_sz$Total / mpsz_sz$area\n\nwrite_rds(mpsz_pa, '../data/rds/mpsz_pa.rds')\nwrite_rds(mpsz_sz, '../data/rds/mpsz_sz.rds')\n\nReference: Matt’s Takehome Exercise 1\n\nmainland_sg &lt;- st_union(mpsz_pa) %&gt;%\n    st_cast(\"POLYGON\")\n\nmainland_sg &lt;- mainland_sg[c(15)]\nmainland_sg &lt;- fill_holes(mainland_sg, units::set_units(1, \"km^2\"))\nmainland_sg &lt;- st_as_sf(mainland_sg)\n\nwrite_rds(mainland_sg, '../data/rds/mainland_sg.rds')\n\nReferences: https://r-spatial.github.io/sf/reference/st_make_grid.html https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/paste\n\nadd_weights &lt;- function(grids, pop) {\n  joined &lt;- st_join(grids, pop, join = st_intersects)  %&gt;%\n    mutate(intersect_area = st_area(x),\n           demand = intersect_area * pop_dens) %&gt;%\n    st_drop_geometry()\n  \n  grids &lt;- grids %&gt;%\n    left_join(joined %&gt;%\n                group_by(ID) %&gt;%\n                summarise(total_demand = sum(demand)),\n              by = \"ID\") %&gt;%\n    mutate(demand = ifelse(is.na(total_demand), 0, total_demand)) %&gt;%\n    select(-total_demand)\n}\n\n\nsg_2_grid &lt;- function(sg, g_size, is_square, name, pop) {\n  grids &lt;- st_make_grid(sg, cellsize = g_size, square = is_square) %&gt;%\n  st_intersection(mainland_sg) %&gt;%\n  st_as_sf() %&gt;%\n    mutate(demand = 0, ID = row_number())\n  \n  grids_w_demand &lt;- add_weights(grids, pop) %&gt;%\n  rename(geometry = x)\n  \n  # Need to modify with weights\n  write_rds(grids_w_demand, paste(name, '.rds', sep = \"\"))\n  \n  return(grids_w_demand)\n}\n\nReferences: https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/dist https://www.rdocumentation.org/packages/geosphere/versions/1.5-18/topics/centroid\n\ngrids_and_dist_matrices &lt;- function(sg, pop, g_size, is_square, subz) {\n  name &lt;- paste('../data/rds/grid_', g_size, ifelse(is_square, \"_square\", \"_hexagon\"), ifelse(subz, \"_sz\", \"_pa\"), sep = \"\")\n  \n  \n  grid &lt;- sg_2_grid(sg, g_size, is_square, name, pop)\n  return(grid)\n}\n\n\nfor(di in c(250, 500, 750, 1000)) {\n  grids_and_dist_matrices(mainland_sg, mpsz_sz, di, FALSE, TRUE)\n  grids_and_dist_matrices(mainland_sg, mpsz_sz, di, TRUE, TRUE)\n  grids_and_dist_matrices(mainland_sg, mpsz_pa, di, FALSE, FALSE)\n  grids_and_dist_matrices(mainland_sg, mpsz_pa, di, TRUE, FALSE)\n}\n\n\nprint(subset(mpsz_pa, Total == 0))\n\nSimple feature collection with 6 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 21140.68 ymin: 27469.57 xmax: 55941.95 ymax: 49122.84\nProjected CRS: SVY21 / Singapore TM\n                PLN_AREA_N Total                       geometry           area\n9  CENTRAL WATER CATCHMENT     0 MULTIPOLYGON (((25028.76 43... 37158689 [m^2]\n11              CHANGI BAY     0 MULTIPOLYGON (((50047.34 37...  1972615 [m^2]\n22             MARINA EAST     0 MULTIPOLYGON (((33223.45 29...  1844044 [m^2]\n23            MARINA SOUTH     0 MULTIPOLYGON (((31494.14 30...  1630376 [m^2]\n42                 SIMPANG     0 MULTIPOLYGON (((31370.51 46...  8283195 [m^2]\n44            STRAITS VIEW     0 MULTIPOLYGON (((31291.53 28...  1127302 [m^2]\n    pop_dens\n9  0 [1/m^2]\n11 0 [1/m^2]\n22 0 [1/m^2]\n23 0 [1/m^2]\n42 0 [1/m^2]\n44 0 [1/m^2]\n\n\n\nset1 &lt;- unique(mpsz_sz$SUBZONE_N)\nset2 &lt;- unique(pop2020_sz$Subzone)\n\n# Find elements that are not shared\nnot_shared &lt;- setdiff(set1, set2)\nnot_shared &lt;- c(not_shared, setdiff(set2, set1)) # Include elements from set2 not in set1\n\n# Print the elements that are not shared\nprint(not_shared)\n\ncharacter(0)"
  },
  {
    "objectID": "prototypes/PointWrangling.html",
    "href": "prototypes/PointWrangling.html",
    "title": "Accessibility Prototype",
    "section": "",
    "text": "pacman::p_load(tidyverse, tmap, sf, dplyr, nngeo, maptools)\n\n\n\n\nsupermarkets &lt;- st_read(\"../data/geospatial/SupermarketsKML.kml\") %&gt;% \n  mutate(Match=str_match_all(Description,\"&lt;td&gt;(.*?)&lt;/td&gt;\")) %&gt;% \n  mutate(Match=map(Match, ~ .[,2])) %&gt;% \n  mutate(Match=map(Match,setNames,c(\"LIC_NAME\", \"BLK_HOUSE\", \"STR_NAME\", \"UNIT_NO\", \"POSTCODE\", \"LIC_NO\", \"INC_CRC\", \"FMEL_UPD_D\"))) %&gt;% \n  unnest_wider(Match) %&gt;%\n  st_as_sf() %&gt;% \n  dplyr::select('LIC_NAME', 'geometry') %&gt;% \n  st_make_valid() %&gt;%\n  st_zm() %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `SUPERMARKETS' from data source \n  `/Users/matthewho/Work/Y3S2/IS415/Project/G1T7-GAA/data/geospatial/SupermarketsKML.kml' \n  using driver `KML'\nSimple feature collection with 526 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6258 ymin: 1.24715 xmax: 104.0036 ymax: 1.461526\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nany(is.na(supermarkets))\n\n[1] FALSE\n\n\n\nsupermarkets$SUBTYPE &lt;- ifelse(grepl(\"FAIRPRICE\", supermarkets$LIC_NAME, ignore.case = TRUE), \"FAIRPRICE\",\n                     ifelse(grepl(\"COLD STORAGE\", supermarkets$LIC_NAME, ignore.case = TRUE), \"COLD STORAGE\",\n                            ifelse(grepl(\"SHENG SIONG\", supermarkets$LIC_NAME, ignore.case = TRUE), \"SHENG SIONG\", \"OTHER\")))\n\n\nfor(st in c(\"FAIRPRICE\", \"COLD STORAGE\", \"SHENG SIONG\", \"OTHER\")) {\n  subset_df &lt;- supermarkets[supermarkets$SUBTYPE == st, ]\n  write_rds(subset_df, paste('../data/rds/supermarkets_', st, '.rds', sep=\"\"))\n}\n\n\nwrite_rds(supermarkets, '../data/rds/supermarkets.rds')\n\n\n\n\n\nmarketandfc &lt;- st_read(\"../data/geospatial/NEAMarketandFoodCentreKML.kml\") %&gt;% \n  mutate(Match=str_match_all(Description,\"&lt;td&gt;(.*?)&lt;/td&gt;\")) %&gt;% \n  mutate(Match=map(Match, ~ .[,2])) %&gt;% \n  mutate(Match=map(Match,setNames,c(\"TOTAL_STALLS\", \"MP_STALLS\", \"CF_STALLS\", \"POSTAL_CODE\", \"OWNER\", \"TYPE\", \"LOCATION_CENTRE\", \"NAME_OF_CENTRE\", \"INC_CRC\", \"FMEL_UP_D\"))) %&gt;% \n  unnest_wider(Match) %&gt;%\n  st_as_sf() %&gt;% dplyr::select(\"NAME_OF_CENTRE\", \"TYPE\", \"TOTAL_STALLS\", \"geometry\") %&gt;% \n  st_make_valid() %&gt;%\n  st_zm() %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MARKET_FOOD_CENTRE' from data source \n  `/Users/matthewho/Work/Y3S2/IS415/Project/G1T7-GAA/data/geospatial/NEAMarketandFoodCentreKML.kml' \n  using driver `KML'\nSimple feature collection with 110 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.7105 ymin: 1.272589 xmax: 103.9882 ymax: 1.443405\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nmarketandfc$SUBTYPE &lt;- ifelse(marketandfc$TYPE == \"HC\", \"HAWKER_CENTRE\",\n                  ifelse(marketandfc$TYPE == \"MHC\", \"MARKET_AND_HAWKER\",\n                         ifelse(marketandfc$TYPE == \"MK\", \"MARKET\", NA)))\nmarketandfc &lt;- subset(marketandfc, select = -TYPE)\n\n\nfor(st in c(\"HAWKER_CENTRE\", \"MARKET_AND_HAWKER\", \"MARKET\")) {\n  subset_df &lt;- marketandfc[marketandfc$SUBTYPE == st, ]\n  write_rds(subset_df, paste('../data/rds/markets_and_food_centres_', st, '.rds', sep=\"\"))\n}\n\n\nwrite_rds(marketandfc, '../data/rds/markets_and_food_centres.rds')\n\n\n\n\n\nmrt &lt;- read.csv('../data/aspatial/mrt.csv') %&gt;%\n  st_as_sf(coords = c(\"lng\", \"lat\"),\n                      crs = 4326) %&gt;%\n  st_transform(crs = 3414) %&gt;%\n  dplyr::select('name', 'geometry')\n\nwrite_rds(mrt, '../data/rds/mrt.rds')\n\n\n\n\n\npoi &lt;- read.csv('../data/aspatial/poi.csv') %&gt;%\n  st_as_sf(coords = c(\"lng\", \"lat\"),\n                      crs = 4326) %&gt;%\n  st_transform(crs = 3414)\n\n\npoi2type &lt;- function(pois, typ) {\n  poi &lt;- pois[pois[[typ]] == 'True', ] %&gt;%\n    dplyr::select('name', 'geometry')\n  write_rds(poi, paste('../data/rds/poi_', typ, '.rds', sep=\"\"))\n}\n\n\npoi_types &lt;- c(\"restaurant\", \"hospital\", \"lodging\", \"bank\", \"cafe\", \"convenience_store\", \"clothing_store\", \"atm\", \"school\", \"beauty_salon\", \"place_of_worship\", \"tourist_attraction\", \"doctor\", \"dentist\", \"gym\", \"night_club\", \"police\", \"library\")\n\nfor (poi_t in poi_types) {\n  poi2type(poi, poi_t)\n}\n\n\n\n\n\nbus_stop &lt;- read_rds(\"../data/rds/osm_sg.rds\")\n\n\nbus_stop &lt;- st_transform(bus_stop, crs=3414)\n\n\nmpsz &lt;- st_read(\"../data/geospatial/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\")\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `/Users/matthewho/Work/Y3S2/IS415/Project/G1T7-GAA/data/geospatial/MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nmpsz &lt;- mpsz %&gt;%\n  mutate(Match=str_match_all(Description,\"&lt;td&gt;(.*?)&lt;/td&gt;\")) %&gt;%\n  mutate(Match=map(Match, ~ .[,2])) %&gt;%\n  mutate(Match=map(Match,setNames,c(\"SUBZONE_NO\",\"SUBZONE_N\",\"SUBZONE_C\",\"CA_IND\", \"PLN_AREA_N\", \"PLN_AREA_C\", \"REGION_N\", \"REGION_C\", \"INC_CRC\", \"FMEL_UPD_D\"))) %&gt;%\n  unnest_wider(Match) %&gt;%\n  st_as_sf()\n\nmpsz &lt;- mpsz %&gt;%\n  dplyr::select('Name', 'geometry', 'SUBZONE_NO', 'SUBZONE_N', 'SUBZONE_C', 'PLN_AREA_N', 'PLN_AREA_C', 'REGION_N', 'REGION_C')\n\nmpsz &lt;- st_make_valid(mpsz)\nmpsz &lt;- st_zm(mpsz)\n\n\nmpsz &lt;- st_transform(mpsz, crs=3414)\n\n\nmerged_sg &lt;- st_union(mpsz) %&gt;%\n    st_cast(\"POLYGON\")\n\nmerged_sg &lt;- merged_sg[c(10)]\nmerged_sg &lt;- st_remove_holes(merged_sg)\nmerged_sg &lt;- st_as_sf(merged_sg)\n\nplot(st_geometry(merged_sg))\n\n\n\n\n\n\n\n\n\nmerged &lt;- as_Spatial(merged_sg)\nmerged_sp &lt;- as(merged, \"SpatialPolygons\")\nmerged_owin &lt;- as(merged_sp, \"owin\")\nwrite_rds(merged_owin, \"../data/rds/merged_owin.rds\")\n\n\nmerged_owin &lt;- read_rds(\"../data/rds/merged_owin.rds\")\n\n\nbus_stop_sg &lt;- st_intersection(bus_stop, merged_sg)\n\n\nbus_stop_sg &lt;- bus_stop_sg %&gt;%\n  dplyr::select(\"osm_id\", \"fclass\", \"name\")\n\n\nwrite_rds(bus_stop_sg, \"../data/rds/bus_stop_sg.rds\")\nbus_stop_sg &lt;- read_rds(\"../data/rds/bus_stop_sg.rds\")"
  },
  {
    "objectID": "prototypes/PointWrangling.html#supermarket",
    "href": "prototypes/PointWrangling.html#supermarket",
    "title": "Accessibility Prototype",
    "section": "",
    "text": "supermarkets &lt;- st_read(\"../data/geospatial/SupermarketsKML.kml\") %&gt;% \n  mutate(Match=str_match_all(Description,\"&lt;td&gt;(.*?)&lt;/td&gt;\")) %&gt;% \n  mutate(Match=map(Match, ~ .[,2])) %&gt;% \n  mutate(Match=map(Match,setNames,c(\"LIC_NAME\", \"BLK_HOUSE\", \"STR_NAME\", \"UNIT_NO\", \"POSTCODE\", \"LIC_NO\", \"INC_CRC\", \"FMEL_UPD_D\"))) %&gt;% \n  unnest_wider(Match) %&gt;%\n  st_as_sf() %&gt;% \n  dplyr::select('LIC_NAME', 'geometry') %&gt;% \n  st_make_valid() %&gt;%\n  st_zm() %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `SUPERMARKETS' from data source \n  `/Users/matthewho/Work/Y3S2/IS415/Project/G1T7-GAA/data/geospatial/SupermarketsKML.kml' \n  using driver `KML'\nSimple feature collection with 526 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6258 ymin: 1.24715 xmax: 104.0036 ymax: 1.461526\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nany(is.na(supermarkets))\n\n[1] FALSE\n\n\n\nsupermarkets$SUBTYPE &lt;- ifelse(grepl(\"FAIRPRICE\", supermarkets$LIC_NAME, ignore.case = TRUE), \"FAIRPRICE\",\n                     ifelse(grepl(\"COLD STORAGE\", supermarkets$LIC_NAME, ignore.case = TRUE), \"COLD STORAGE\",\n                            ifelse(grepl(\"SHENG SIONG\", supermarkets$LIC_NAME, ignore.case = TRUE), \"SHENG SIONG\", \"OTHER\")))\n\n\nfor(st in c(\"FAIRPRICE\", \"COLD STORAGE\", \"SHENG SIONG\", \"OTHER\")) {\n  subset_df &lt;- supermarkets[supermarkets$SUBTYPE == st, ]\n  write_rds(subset_df, paste('../data/rds/supermarkets_', st, '.rds', sep=\"\"))\n}\n\n\nwrite_rds(supermarkets, '../data/rds/supermarkets.rds')"
  },
  {
    "objectID": "prototypes/PointWrangling.html#market-food-centre",
    "href": "prototypes/PointWrangling.html#market-food-centre",
    "title": "Accessibility Prototype",
    "section": "",
    "text": "marketandfc &lt;- st_read(\"../data/geospatial/NEAMarketandFoodCentreKML.kml\") %&gt;% \n  mutate(Match=str_match_all(Description,\"&lt;td&gt;(.*?)&lt;/td&gt;\")) %&gt;% \n  mutate(Match=map(Match, ~ .[,2])) %&gt;% \n  mutate(Match=map(Match,setNames,c(\"TOTAL_STALLS\", \"MP_STALLS\", \"CF_STALLS\", \"POSTAL_CODE\", \"OWNER\", \"TYPE\", \"LOCATION_CENTRE\", \"NAME_OF_CENTRE\", \"INC_CRC\", \"FMEL_UP_D\"))) %&gt;% \n  unnest_wider(Match) %&gt;%\n  st_as_sf() %&gt;% dplyr::select(\"NAME_OF_CENTRE\", \"TYPE\", \"TOTAL_STALLS\", \"geometry\") %&gt;% \n  st_make_valid() %&gt;%\n  st_zm() %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MARKET_FOOD_CENTRE' from data source \n  `/Users/matthewho/Work/Y3S2/IS415/Project/G1T7-GAA/data/geospatial/NEAMarketandFoodCentreKML.kml' \n  using driver `KML'\nSimple feature collection with 110 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.7105 ymin: 1.272589 xmax: 103.9882 ymax: 1.443405\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nmarketandfc$SUBTYPE &lt;- ifelse(marketandfc$TYPE == \"HC\", \"HAWKER_CENTRE\",\n                  ifelse(marketandfc$TYPE == \"MHC\", \"MARKET_AND_HAWKER\",\n                         ifelse(marketandfc$TYPE == \"MK\", \"MARKET\", NA)))\nmarketandfc &lt;- subset(marketandfc, select = -TYPE)\n\n\nfor(st in c(\"HAWKER_CENTRE\", \"MARKET_AND_HAWKER\", \"MARKET\")) {\n  subset_df &lt;- marketandfc[marketandfc$SUBTYPE == st, ]\n  write_rds(subset_df, paste('../data/rds/markets_and_food_centres_', st, '.rds', sep=\"\"))\n}\n\n\nwrite_rds(marketandfc, '../data/rds/markets_and_food_centres.rds')"
  },
  {
    "objectID": "prototypes/PointWrangling.html#mrt",
    "href": "prototypes/PointWrangling.html#mrt",
    "title": "Accessibility Prototype",
    "section": "",
    "text": "mrt &lt;- read.csv('../data/aspatial/mrt.csv') %&gt;%\n  st_as_sf(coords = c(\"lng\", \"lat\"),\n                      crs = 4326) %&gt;%\n  st_transform(crs = 3414) %&gt;%\n  dplyr::select('name', 'geometry')\n\nwrite_rds(mrt, '../data/rds/mrt.rds')"
  },
  {
    "objectID": "prototypes/PointWrangling.html#poi",
    "href": "prototypes/PointWrangling.html#poi",
    "title": "Accessibility Prototype",
    "section": "",
    "text": "poi &lt;- read.csv('../data/aspatial/poi.csv') %&gt;%\n  st_as_sf(coords = c(\"lng\", \"lat\"),\n                      crs = 4326) %&gt;%\n  st_transform(crs = 3414)\n\n\npoi2type &lt;- function(pois, typ) {\n  poi &lt;- pois[pois[[typ]] == 'True', ] %&gt;%\n    dplyr::select('name', 'geometry')\n  write_rds(poi, paste('../data/rds/poi_', typ, '.rds', sep=\"\"))\n}\n\n\npoi_types &lt;- c(\"restaurant\", \"hospital\", \"lodging\", \"bank\", \"cafe\", \"convenience_store\", \"clothing_store\", \"atm\", \"school\", \"beauty_salon\", \"place_of_worship\", \"tourist_attraction\", \"doctor\", \"dentist\", \"gym\", \"night_club\", \"police\", \"library\")\n\nfor (poi_t in poi_types) {\n  poi2type(poi, poi_t)\n}"
  },
  {
    "objectID": "prototypes/PointWrangling.html#bus-stop",
    "href": "prototypes/PointWrangling.html#bus-stop",
    "title": "Accessibility Prototype",
    "section": "",
    "text": "bus_stop &lt;- read_rds(\"../data/rds/osm_sg.rds\")\n\n\nbus_stop &lt;- st_transform(bus_stop, crs=3414)\n\n\nmpsz &lt;- st_read(\"../data/geospatial/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\")\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `/Users/matthewho/Work/Y3S2/IS415/Project/G1T7-GAA/data/geospatial/MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nmpsz &lt;- mpsz %&gt;%\n  mutate(Match=str_match_all(Description,\"&lt;td&gt;(.*?)&lt;/td&gt;\")) %&gt;%\n  mutate(Match=map(Match, ~ .[,2])) %&gt;%\n  mutate(Match=map(Match,setNames,c(\"SUBZONE_NO\",\"SUBZONE_N\",\"SUBZONE_C\",\"CA_IND\", \"PLN_AREA_N\", \"PLN_AREA_C\", \"REGION_N\", \"REGION_C\", \"INC_CRC\", \"FMEL_UPD_D\"))) %&gt;%\n  unnest_wider(Match) %&gt;%\n  st_as_sf()\n\nmpsz &lt;- mpsz %&gt;%\n  dplyr::select('Name', 'geometry', 'SUBZONE_NO', 'SUBZONE_N', 'SUBZONE_C', 'PLN_AREA_N', 'PLN_AREA_C', 'REGION_N', 'REGION_C')\n\nmpsz &lt;- st_make_valid(mpsz)\nmpsz &lt;- st_zm(mpsz)\n\n\nmpsz &lt;- st_transform(mpsz, crs=3414)\n\n\nmerged_sg &lt;- st_union(mpsz) %&gt;%\n    st_cast(\"POLYGON\")\n\nmerged_sg &lt;- merged_sg[c(10)]\nmerged_sg &lt;- st_remove_holes(merged_sg)\nmerged_sg &lt;- st_as_sf(merged_sg)\n\nplot(st_geometry(merged_sg))\n\n\n\n\n\n\n\n\n\nmerged &lt;- as_Spatial(merged_sg)\nmerged_sp &lt;- as(merged, \"SpatialPolygons\")\nmerged_owin &lt;- as(merged_sp, \"owin\")\nwrite_rds(merged_owin, \"../data/rds/merged_owin.rds\")\n\n\nmerged_owin &lt;- read_rds(\"../data/rds/merged_owin.rds\")\n\n\nbus_stop_sg &lt;- st_intersection(bus_stop, merged_sg)\n\n\nbus_stop_sg &lt;- bus_stop_sg %&gt;%\n  dplyr::select(\"osm_id\", \"fclass\", \"name\")\n\n\nwrite_rds(bus_stop_sg, \"../data/rds/bus_stop_sg.rds\")\nbus_stop_sg &lt;- read_rds(\"../data/rds/bus_stop_sg.rds\")"
  },
  {
    "objectID": "prototypes/KDEPrototype.html",
    "href": "prototypes/KDEPrototype.html",
    "title": "WhatTown",
    "section": "",
    "text": "pacman::p_load(tidyverse, sf, tmap, maptools, spatstat, raster, tidyr, readxl, sp)\n\n\npop2020 &lt;- read_excel(\"../data/aspatial/Singapore Census of Population (2020).xlsx\", sheet=2, skip=4, col_names=TRUE)\nmpsz &lt;- read_rds(\"../data/rds/mpsz.rds\")\n\nRemove rows that are all NA:\n\npop2020 &lt;- pop2020[rowSums(is.na(pop2020)) != ncol(pop2020),]\n\nRename col, remove all rows where any other column except first column is NA. Remove rows where the first column is “Planning Area of Residence” - indicates start of new page, useless.\n\ncolnames(pop2020)[1] = \"Planning_Area\"\ncols_to_check &lt;- names(pop2020)[-1]\npop2020 &lt;- pop2020[complete.cases(pop2020[, cols_to_check]), ]\npop2020 &lt;- pop2020[!(pop2020$Planning_Area %in% \"Planning Area of Residence\"),]\n\nUse function to replace all missing values (NA) with the last non-missing value, will help to fill up subzones with its proper planning area.\n\nfill_missing &lt;- function(x) {\n  non_na_index &lt;- which(!is.na(x))\n  last_non_na &lt;- NA\n  for (i in 1:length(x)) {\n    if (is.na(x[i])) {\n      if (!is.na(last_non_na)) {\n        x[i] &lt;- x[last_non_na]\n      }\n    } else {\n      last_non_na &lt;- i\n    }\n  }\n  return(x)\n}\n\npop2020$Planning_Area &lt;- fill_missing(pop2020$Planning_Area)\n\nReplace - with 0.\n\ndata_columns &lt;- names(pop2020)[-1]\npop2020[, data_columns] &lt;- lapply(pop2020[, data_columns], function(x) gsub(\"-\", \"0\", x))\n\n\npop2020$Planning_Area &lt;- gsub(\"\\r\\n\", \"\", pop2020$Planning_Area)\npop2020$Subzone &lt;- gsub(\"\\r\\n\", \"\", pop2020$Subzone)\npop2020$Subzone &lt;- gsub(\"0\", \"-\", pop2020$Subzone)\npop2020$Subzone &lt;- toupper(pop2020$Subzone)\n\npop2020$Subzone &lt;- gsub(\"KANGNORTH\", \"KANG NORTH\", pop2020$Subzone)\n\npop2020$Planning_Area &lt;- toupper(pop2020$Planning_Area)\npop2020filtered &lt;- pop2020[pop2020$Subzone != \"TOTAL\",]\n\nmerged &lt;- merge(mpsz, pop2020filtered, by.x=\"SUBZONE_N\", by.y=\"Subzone\")\nwrite_rds(pop2020filtered, '../data/rds/pop2020.rds')\n\n\nsupermarkets &lt;- read_rds(\"../data/rds/supermarkets.rds\")\n\n\nsupermarkets_sp &lt;- as_Spatial(supermarkets)\n\n\nsupermarkets_sp &lt;- as(supermarkets_sp, \"SpatialPoints\")\n\n\nsupermarkets_ppp &lt;- as(supermarkets_sp, \"ppp\")\nsupermarkets_ppp\n\nPlanar point pattern: 526 points\nwindow: rectangle = [4901.19, 46948.23] x [25529.08, 49233.6] units\n\n\n\nplot(supermarkets_ppp)\n\n\n\n\n\n\n\n\n\nany(duplicated(supermarkets_ppp))\n\n[1] TRUE\n\n\n\nsupermarkets_ppp_jit &lt;- rjitter(supermarkets_ppp,\n                                retry=TRUE,\n                                nsim=1,\n                                drop=TRUE)\n\n\nany(duplicated(supermarkets_ppp_jit))\n\n[1] FALSE\n\n\n\nmerged_owin &lt;- read_rds(\"../data/rds/merged_owin.rds\")\n\n\nsupermarketsSG_ppp = supermarkets_ppp[merged_owin]\n\n\nplot(supermarketsSG_ppp)\n\n\n\n\n\n\n\n\n\nsupermarketsSG_ppp.km &lt;- rescale(supermarketsSG_ppp, 1000, \"km\")\npar(mfrow=c(2,2), mar=c(3,3,1,3))\nplot(density(supermarketsSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\nplot(density(supermarketsSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\n\nWarning in density.ppp(supermarketsSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nplot(density(supermarketsSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\n\nWarning in density.ppp(supermarketsSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nplot(density(supermarketsSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")\n\nWarning in density.ppp(supermarketsSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\n\n\n\n\n\n\n\n\n\npar(mfrow=c(1,2))\nplot(density(supermarketsSG_ppp.km,\n             sigma=bw.ppl,\n             edge=TRUE,\n             kernel=\"gaussian\"),\n     main=\"Fixed bandwidth\")\nplot(adaptive.density(supermarketsSG_ppp.km,\n                      method=\"kernel\"),\n     main=\"Adaptive bandwidth\")\n\n\n\n\n\n\n\n\n\nkde_supermarketsSG.bw &lt;- density(supermarketsSG_ppp.km,\n             sigma=bw.ppl,\n             edge=TRUE,\n             kernel=\"gaussian\")\n\n\ngridded_kde_supermarketsSG_bw &lt;- as.SpatialGridDataFrame.im(kde_supermarketsSG.bw)\nspplot(gridded_kde_supermarketsSG_bw)\n\n\n\n\n\n\n\n\n\nkde_supermarketsSG_bw_raster &lt;- raster(gridded_kde_supermarketsSG_bw)\nkde_supermarketsSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.3807546, 0.2250614  (x, y)\nextent     : 2.667537, 51.40413, 21.44848, 50.25633  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -9.858872e-16, 6.755265  (min, max)\n\n\n\nprojection(kde_supermarketsSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414 +units=km\")\nkde_supermarketsSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.3807546, 0.2250614  (x, y)\nextent     : 2.667537, 51.40413, 21.44848, 50.25633  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=km +no_defs \nsource     : memory\nnames      : v \nvalues     : -9.858872e-16, 6.755265  (min, max)\n\n\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_basemap(server=\"OpenStreetMap.HOT\") +\n  tm_basemap(server = \"Esri.WorldImagery\") +\n  tm_shape(kde_supermarketsSG_bw_raster) +\n  tm_raster(\"v\",\n            title = \"Kernel Density\",\n            style = \"pretty\",\n            alpha = 0.6,\n            palette = c(\"#fafac3\",\"#fd953b\",\"#f02a75\",\"#b62385\",\"#021c9e\")) +\n  tm_shape(merged)+\n  tm_polygons(alpha=0.1,\n              id=\"PLN_AREA_N\", \n              popup.vars=c(\n                \"SUBZONE_N\",\n                \"Total\",\n                \"0 - 4\",\n                \"5 - 9\",\n                \"10 - 14\",\n                \"15 - 19\",\n                \"20 - 24\",\n                \"25 - 29\",\n                \"30 - 34\",\n                \"35 - 39\",\n                \"40 - 44\",\n                \"45 - 49\",\n                \"50 - 54\",\n                \"55 - 59\",\n                \"60 - 64\",\n                \"65 - 69\",\n                \"70 - 74\",\n                \"75 - 79\",\n                \"80 - 84\",\n                \"85 - 89\",\n                \"90 & Over\"\n              ))+\n  tmap_options(check.and.fix = TRUE)\n\n\n\n\n\n2OSPPA using Aljunied\n\nmpsz &lt;- as_Spatial(mpsz)\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 332 \nextent      : 2667.537, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 7\nnames       :   Name, SUBZONE_NO, SUBZONE_N, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C \nmin values  :  kml_1,          1, ADMIRALTY, ANG MO KIO,         AM, CENTRAL REGION,       CR \nmax values  : kml_99,          9,    YUNNAN,     YISHUN,         YS,    WEST REGION,       WR \n\n\n\naj = mpsz[mpsz@data$SUBZONE_N == \"ALJUNIED\",]\naj_sp = as(ls, \"SpatialPolygons\")\naj_owin = as(ls_sp, \"owin\")\naj_ppp = supermarkets_ppp_jit[aj_owin]\nG_aj = Gest(aj_ppp, correction = \"border\")\nplot(G_aj, xlim=c(0,500))\n\n\nF_aj = Fest(aj_ppp)\nplot(F_aj)\n\n\nK_aj = Kest(aj_ppp, correction = \"Ripley\")\nplot(K_aj, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\nL_aj = Lest(aj_ppp, correction=\"Ripley\")\nplot(L_aj, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")"
  }
]